<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>RAG Summary</title>
    <link href="/2025/01/04/RAG_summary/RAG_summary/"/>
    <url>/2025/01/04/RAG_summary/RAG_summary/</url>
    
    <content type="html"><![CDATA[<h1 id="rag-summary">RAG Summary</h1><h2 id="background">Background</h2><h2 id="definitions">1. Definitions</h2><blockquote><p><strong>检索增强生成技术（RAG）：</strong>RAG是一种将用户输入内容和知识库中的已有知识进行匹配，筛选出最相关的一条或多条知识，然后通过prompt对用户输入内容和筛选出的内容进行整合输入大语言模型，以得到更高质量输出内容的自然语言处理方法。</p></blockquote><figure><img src="3916b75496194ffaac3e4991e5da56c4_t75jpibqm.png"alt="3916b75496194ffaac3e4991e5da56c4" /><figcaptionaria-hidden="true">3916b75496194ffaac3e4991e5da56c4</figcaption></figure><h2 id="different-types">2. Different Types</h2><p><strong>(1) from retrival methods</strong> -word-based：直接使用字符串匹配 -vector-based：将字符串进行嵌入再比较</p><p><strong>(2) from retrival granularity</strong> - chunk retrival -token retrival - entity retrival</p><p><strong>(3) from generation methods</strong> -开源语言模型，可以调整参数 - 闭源语言模型，不可调整参数</p><p><strong>(4) from integration methods</strong>(将retrival的内容和原问题整合) -输入层整合：比如，直接在大模型输入中通过prompt对retrival的内容和原问题进行拼接-中间层整合：比如，先分别对retrival的内容和原问题进行encoder，再整合成一高维张量进行decoder，但此类方法一般需要对原模型参数进行调整</p><p><strong>(4) from training methods</strong></p><ul><li>trainingbased：调整模型参数，可以分别独立训练检索器和大语言模型的参数，也可以联合训练，也可以联合检索器和大语言模型，但先调整检索器的参数，再调整大语言模型的参数。</li><li>training free：冻结模型参数，一般只使用提示工程对prompt进行调整</li></ul><figure><img src="a6773b8da41c4ae4850f817897cd0c44.png"alt="a6773b8da41c4ae4850f817897cd0c44" /><figcaptionaria-hidden="true">a6773b8da41c4ae4850f817897cd0c44</figcaption></figure><h1 id="section"></h1><h2 id="advantages-and-challenges">3. Advantages and Challenges</h2><p><strong>(1) Advantages</strong> -有效解决因大语言模型训练过程中缺乏问题回答所需的特定领域知识或者即时知识而造成错误回答的问题，并且在给定检索到的相关知识的情况下，大模型幻觉问题可以得到有效解决，回答的内容质量也将更更高。-相比通过某一些领域的特定训练语料库，使用大量计算资源微调大语言模型以使其适应此领域问题的回答，使用已有的RAG框架更加方便高效，只需要对知识库进行调整使其包含特定领域的相关知识。</p><p><strong>(2) Challenges of Original RAG Framework</strong> -知识库中的内容很难保证绝对正确，有时错误或者无效的知识(Noise)反而可能会误导大语言模型作出错误的回答。（CorrectiveRetrieval Augmented Generation,Self-RAG）可以考虑添加一个能够识别检索的知识是否有关+正确的小模型。 -当知识库中的知识数目日益增多时，如何在尽可能少的时间里高效地抽取有效的信息，尽可能少地抽取无关信息，也是需要考虑的问题。（DEMONSTRATE–SEARCH–PREDICT--将retrival大语言模型和对话大语言模型交互，通过多轮对话抽取出有效的信息，RETRO，或者也可以考虑对检索粒度的一些调整）- 知识库中直接抽取出的知识可能会存在无关文本(noise, irreverenttexts)or错误文本(error)or不完整的但可以补全成相关信息的文本，如何进一步提炼出无无关or错误的信息，将不完整信息补全的新文本也是应该关注的。-目前RAG大多局限于存取文本信息，如何将可存取的内容扩展到Graph等多模态内容也是可以改进的要点。-在存储文本信息于知识库中时，受限于单个文本块的长度限制，大多会将文本进行截断存储，但是在截断的时候可能文本的含义会发生改变，可能存在语义信息的丢失。-在从知识库中检索有关知识时，因为文本块的长度一般固定不变，并且一般固定了取回的文本块数目，所以不可避免地会检索到一些与问题回答无关的内容，但这些无关的内容可能会导致大模型幻觉加剧，回答质量降低，如何尽可能减少检索结果中的无关内容并对检索结果中的无关内容进行筛除也是可以改进的方向，比如可以考虑可变长度的检索内容，当相关内容多就适当多取回一些内容。（<strong>FILCO</strong>Learning to Filter Context for Retrieval-Augmented Generation） -大语言模型输入内容长度一般会有限制，将检索到的内容直接拼接可能会超过其最大长度，使用支持更大长度输入的大语言模型也会增大其计算复杂度。（<strong><em>FiD</em></strong>Leveraging Passage Retrieval with Generative Models for Open DomainQuestion Answering） -传统的RAG的知识库中的内容在不手动更新的情况下内容是一成不变的，借助网络搜索引擎可以搜索到最新的信息，以提高一些包括即时突发事件的问题的回答准确率。（Internet-AugmentedDialogue Generation） -RAG的初衷是使在不需对模型进行大规模的调整，仅仅对模型进行拼接微调的情况下，达到到较好的回答质量，但是现在许多新的pipline似乎都与之背道而驰，将pipline设计得越来越复杂，导致计算量加大，响应时间变长。- retriver和generator之间可能存在gap需要一个合适的bridge衔接。 -传统的RAG一般对问题调用单一的知识库，可以考虑对问题进行简单分析，依据问题类型调用针对此类型问题的知识库or针对此类型问题小工具or不调用（LLM自身的知识已经可以解决），比如：对论文类问题调用论文知识库，对数学问题调用计算工具，对天气时间问题调用对应API。(构建树状知识库)这样可能可以检索到对回答有作用+语义相关的检索结果 i.e. Can you help meto make a trip plan for Hanoi? <strong>Database A: Prose</strong>1--Hanoi is my hometown, I love it, go there for trip is great.2--Vietam is my mother country, I love it, go there for trip is great.<strong>Database B: Trip Plan</strong> 1--If you come to Hanoi, you cango to train street and Longbien River Bank. if using the usual RAGpipline, A-1 will be chosen. By contrast, if using the new pipline, B-2,useful in solving question, will be chosed. In addition,不调用的情况：send the question into LLM directly, and the output passesresonance evaluation machine(check 是否逻辑or事实错误) and relativeevaluation machine(check是否答非所问,是否空洞泛谈)</p><ul><li>如何衔接不同语言之间的Gap</li><li>当检索知识和Generator本身的知识冲突，并且只有一个是正确时，Generator可能无法选择正确的知识回答。</li></ul><h1 id="rag-enhancement-direction">5. RAG Enhancement Direction</h1><figure><img src="image.png" alt="alt text" /><figcaption aria-hidden="true">alt text</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>RAG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Benchmark in RAG Summary</title>
    <link href="/2025/01/04/Benchmark_in_RAG_Summary/Benchmark_in_RAG_Summary/"/>
    <url>/2025/01/04/Benchmark_in_RAG_Summary/Benchmark_in_RAG_Summary/</url>
    
    <content type="html"><![CDATA[<h1 id="benchmark-in-rag-summary">Benchmark in RAG Summary</h1><h3 id="union-paradigm-of-rag-benchmark">1. Union Paradigm of RAGBenchmark</h3><figure><img src="IMG_9A4EFC9FC7BA-1.jpeg#w80" alt="alt text" /><figcaption aria-hidden="true">alt text</figcaption></figure><h3 id="classification-of-benchmark">2. Classification of Benchmark</h3><pre><code class=" mermaid">   %%&#123; init: &#123;&quot;themeVariables&quot;: &#123; &quot;fontSize&quot;: &quot;22px&quot;, &quot;nodeWidth&quot;: 120, &quot;nodeHeight&quot;: 30 &#125; &#125; &#125;%%graph   Main(Benchmark) --&gt; 1(按照应用领域分类)   1 --&gt; 1-1(Universal benchmark)   1 --&gt; 1-2(Task-specific Benchmark)   Main --&gt; 2(按照数据性质分类)   2 --&gt; 2-1(应用Benchmark)   2 --&gt; 2-2(合成Benchmark)   Main --&gt; 3(按照评估范围分类)   3 --&gt; 3-1(Micro-benchmark)   3 --&gt; 3-2(Macro-benchmark)   Main --&gt; 4(按照自动化程度分类)   4 --&gt; 4-1(Manual-benchmark)   4 --&gt; 4-2(Auto-benchmark)</code></pre><ol type="1"><li>按照应用领域分类：</li></ol><ul><li>Universal benchmark：适用于广泛的应用场景。</li><li>Task-specific Benchmark：针对特定task的需求设计。</li></ul><ol start="2" type="1"><li>按照数据类型分类：</li></ol><ul><li>应用Benchmark：基于真实数据评估。</li><li>合成Benchmark：基于人造的虚拟信息评估（比如在RAG中创建一些新的不存在的名词对应的知识作为检索结果，以评估Generator在面对新知识的表现）。</li></ul><ol start="3" type="1"><li>按照评估范围分类：</li></ol><ul><li>Micro-benchmark：专门测试模型的一个模块。</li><li>Macro-benchmark：对整个模型进行综合性的性能评估。</li></ul><ol type="1"><li>按照评估样本来源分类：</li></ol><ul><li>Manual-benchmark：评估样本需要手动标注。</li><li>Auto-benchmark：评估样本通过LLM自动生成，无需手动标注即可生成大量高质量样本。</li></ul><h3 id="current-paradigm-of-rag-benchmark">3. Current Paradigm of RAGBenchmark</h3><p><strong>1. Generator Specific Benchmark</strong>一类Benchmark主要用于评估Generator本身，具体实例如下：1）提出RAG需要具备分辨知识是否有用，是否是错误知识的两种能力，提出两种evaluationmetrics进行评估。 <img src="image-11.png#w50" alt="alt text" />2）构建自动的RAG评估体系，首先使用LLM通过少量样本与文本自动构建出大量样本以供评估RAG的Generator的表现效果；（构建样本包括正样本，弱负样本，强负样本）然后使用原有样本与自动构建的样本对Generator进行评估；最后通过评估得出Generator评分的概率分布，最后找出95%置信度的置信区间的中点作为Generator的评分。<img src="image-12.png#w70" alt="alt text" />3）提出RAG需要具备的四种能力，使用GPT与Documents构建基本的QA数据集，然后使用searchengine添加Question的RetrieveInfo得到QRA数据集，最后针对四种能力分别构建四个针对性的testbed（数据集）使用相关指标进行评估。 <img src="image-13.png#w60"alt="alt text" /> <strong>2. End to End Benchmark</strong>另一类Benchmark既可以评估Retriver，Generator，也可以评估OverallPerformance，具体实例如下：1）将多个原始的QA数据集进行扩展，得到QRA数据集，并使用Llama 3 basedRefChecker对R和A的部分annotate相关标签，使用以下评估指标全面评估： <imgsrc="image-10.png#w80" alt="alt text" /></p><h3 id="challenges-of-current-paradigm-of-rag-benchmark">3. Challengesof Current Paradigm of RAG Benchmark</h3><ol type="1"><li>缺乏Noise Specific Benchmark。</li><li>部分benchmark还在使用BLEU，ROUGEL，ACC等通用评估指标，没有提出相关的task-specific评估指标</li><li>大多数benchmark缺乏针对[noise占retrieveinfo不同比例]，[不同类型noise]情况下的结果进行定量分析。</li><li>大多数Benchmark缺乏noise robustness evaluation metrics，缺乏noisedataset。</li><li>大多数benchmark评估需要依赖groundtruth，对于一些开放性问题容易受到ground truth的bias影响。</li><li>大多数benchmark局限于对Generator进行评估，忽略了对Retriever与overallmodel的评估。</li><li>目前评估RAG时有一些方法使用的是[Q, 单一retrieve documnt,A]训练，而RAG实际使用情况下可能是依托多retrieve document作出回答。</li></ol>]]></content>
    
    
    <categories>
      
      <category>RAG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Noise in RAG Summary</title>
    <link href="/2025/01/04/Noise_in_RAG_Summary/Noise_in_RAG_Summary/"/>
    <url>/2025/01/04/Noise_in_RAG_Summary/Noise_in_RAG_Summary/</url>
    
    <content type="html"><![CDATA[<h1 id="noise-in-rag-summary">Noise in RAG Summary</h1><h3 id="i.-the-definition-of-retrieval-noise-in-rag">I. The Definitionof Retrieval Noise in RAG</h3><p><strong>Retrieval noise</strong> refers to irrelevant,counterfactual, or vague information retrieved from an externalknowledge base that does not contribute to the generation of a correctresponse. (It may mislead the generation by offering conterfactual infoor intervening the LLM to focus on the useful info)</p><h3 id="ii.-taxonomy-of-retrival-info-noise">II. Taxonomy of RetrivalInfo (Noise)</h3><p>Relevant in the following graph denotes info with high semanticsimilarity to the qustion. <pre><code class=" mermaid">   %%&#123; init: &#123;&quot;themeVariables&quot;: &#123; &quot;fontSize&quot;: &quot;22px&quot;, &quot;nodeWidth&quot;: 120, &quot;nodeHeight&quot;: 30 &#125; &#125; &#125;%%graph    Main[Retrival Info]   Main --&gt; A[Noise]   Main --&gt; B[Useful Info]   A --&gt; A1(Persistent Misinfo)   A1 --&gt; A1a(relevant PM)   A1 --&gt; A1b(irrelevant PM)   A --&gt; A2(Obsolete Info)   A2 --&gt; A2a(relevant OI)   A2 --&gt; A2b(irrelevant OI)   A --&gt; A3(Ambiguous Info)   A3 --&gt; A3a(relevant AI)   A3 --&gt; A3b(irrelevant AI)   A --&gt; A4(Inconsequential Info)   A4 --&gt; A4a(relevant II)   A4 --&gt; A4b(irrelevant II)   B --&gt; B1(Golden Info)   B --&gt; B2(Intermediate Info)</code></pre> #### Examples <strong>1.Question:</strong> Who is the grandpa of Barron Trump?</p><p><strong>2. Retrieved Info:</strong> 1) Intermediate Info: DonaldTrump is the farther of Barron Trump. 2) Intermediate Info: Fred Trumpis the farther of Donald Trump. 3) Golden Info: Fred Trump is thegrandpa of Barron Trump. 4) Persistent Misinfo: Macron is the presidentof the US now. 5) Obsolete Info: Obama is the president of the US now.6) Ambiguous Info: Do you know who is Trump? 7) Inconsequential Info:Trump used to be the president of the US.</p><h3 id="iii.-current-paradigm-to-deal-with-the-retrieval-noise">III.Current Paradigm to Deal with the Retrieval Noise</h3><p><strong>1. Task Specific Dataset Construction</strong>为应对不同类型的Noise对RAG生成产生的影响，其中一类方法是为针对Noise构建特定的数据集，具体实例如下：</p><p>1）通过构造包含Retrieval Noise的QRA数据集,并在QRA数据集上对LLM模型进行微调。 [Question, Retrival Documents(including Retrieval Noise), Answer] 让模型对RetrievalNoise“见多识广”，具备区分Retrieval Noise和Useful Info的能力； <imgsrc="image-3.png#w40" alt="alt text" /></p><p>2）有一点点类似于CoT的思想，通过构造Answer包含【区分RetrievalNoise】，【对Retrieval Info进行推理】等内容的reasoning-augmentatedQRA数据集并微调。 [Question, Retrival Documents, Answer(includingreasoning process)] 此类数据集的Answer包括问题分解，将retrivalinfo进行筛选等过程，这样可以强化模型逻辑推理能力与信息筛选能力，让训练后的模型输出不受RetrievalNoise干扰的正确回答。 <img src="image-2.png" alt="alt text" /></p><p><strong>2. Applying New Training Paradigm</strong>另类方法是针对Noise设定特定的训练方法与损失函数对LLM进行微调，具体实例如下：</p><p>1）通过分层训练的方法，让LLM先具备识别RetrievalNoise的能力，再让LLM具备不受Retrieval Noise干扰作出正确Answer的能力；备注：此实例目前没有相关研究，下图为应对命名实体识别的类似实例示意图。<img src="image-4.png" alt="alt text" /></p><p>2）使用一些特定的学习范式，比如对比学习，自适应学习，对抗训练等。<img src="image-9.png" alt="alt text" /></p><p><strong>3. Add Extra Verification Distill Module</strong>最后一类方法即在Retriver和LLM中间加入一个检验模块筛选模块，将检索到的信息进行重排序or将检索到的信息进行提炼整合，筛除RetrieveNoise。 <strong>E1</strong> <img src="image-5.png" alt="alt text" /><strong>E2</strong> <img src="image-7.png" alt="alt text" /><strong>E3</strong> <img src="image-8.png" alt="alt text" /></p><h3 id="iv.-current-challenges-of-retrieval-noise">IV. CurrentChallenges of Retrieval Noise</h3><p>在RAG系统中，当Top-k检索的k值增大时，有助于问题回答的信息包含在检索文档中的可能性逐渐增大，但也同时不可避免地引入检索噪声(RetrievalNoise)。RetrivalNoise中的反事实信息，有歧义信息可能会误导使用错误知识作出回答，RetrivalNoise中的正确无用信息可能会导致模型对有助于问题回答的信息关注程度下降，最终使得模型回答质量急剧下降。</p><p>针对RetrivalNoise严重影响RAG生成质量这一问题，诸多不同范式的解决方案也随之提出。然而这些方法普遍存在如下共性问题：</p><ol type="1"><li>噪声类别的局限性：目前的方法大多针对某一种特定类型的噪声，例如相关但无用的文本或反事实文本（counterfactualtext）。这导致它们缺乏针对所有噪声的统一解决方案，难以保证LLM在多种噪声共存的复杂环境下作出准确回答。</li><li>缺乏系统性分类和全面评估：现有研究中，针对RAG系统中噪声的分类缺乏系统性，目前少有研究完整地揭示不同类型噪声对生成质量的具体影响。</li><li>缺乏统一的噪声数据集与评估体系：缺乏统一标准的现状，使得各研究结果难以横向对比，限制了新方法的进一步发展。</li><li>当前方法的LLM或Extra Verification DistillModule是否会对与Question包含相同概念但表述方式不同的UsefulInfo误判为Noise(相关无用Noise)，是否会对一些特别新的UsefulInfo误判为Noise(反事实Noise)？（当前QRA训练数据集的R缺少与Question包含相同概念但表述方式不同的UsefulInfo）</li><li>当前的方法难以让模型识别过时信息以及一些小众的永久反事实信息(比如凭空捏造的一些实体与其关系等)，因为他们没有内在共同点，也无法保证所有的过时信息和小众的永久反事实信息都被训练到，并且过时信息永远都在变化。</li><li>解决RetrievalNoise这一问题需要使RAG同时获得识别Noise与充分使用UsefulInfo的能力。单一地添加Extra Verification DistillModule(获得识别Noise和UsefulInfo的能力)，而不对LLM进行微调(没有使其获得正确使用UsefulInfo的能力)，是否会出现LLM内部知识与UsefulInfo冲突的情况，导致无法充分使用Useful Info作出回答。</li><li>目前的解决方法大多关注在Generator上，也需要从Retriever的角度考虑如何解决Noise问题。</li><li>目前训练Noise RAG时有一些方法使用的是[Q, 单一retrieve documnt,A]训练，而RAG实际使用情况下可能是依托多retrieve document作出回答。</li></ol>]]></content>
    
    
    <categories>
      
      <category>RAG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在使用py2app打包python文件时遇到的一些问题与顺便学习到的知识点</title>
    <link href="/2024/08/09/software%20packing/"/>
    <url>/2024/08/09/software%20packing/</url>
    
    <content type="html"><![CDATA[<h2 id="序言">序言</h2><p><strong>py2app</strong>：Create standalone Mac OS X applications withPython， but the app still have to use the python interpreter to run.<strong>PyInstaller</strong>：Create standalone Mac OS X app, Window appand Linux app with Python， and the app can run through binary filedirectly without interpreting. ## 1. 使用Py2app打包的方法及原理 <ahref="https://py2app.readthedocs.io/en/latest/tutorial.html">https://py2app.readthedocs.io/en/latest/tutorial.html</a></p><p>使用 py2app 封装的 macOS 应用程序通常是一个 .app文件夹，它包含所有必要的资源和库文件，以使应用程序能够在没有安装 Python解释器或其他依赖库的情况下运行。 一个使用 py2app 创建的 macOS应用程序通常包含以下组成部分：</p><ul><li>Application 文件夹: 这是一个包含所有应用程序资源的文件夹，通常命名为<AppName>.app。</li><li>Contents 文件夹: 这个文件夹包含了应用程序的所有组成部分。 它通常位于<AppName>.app 文件夹内。</li><li>MacOS 文件夹: 这个文件夹包含了应用程序的可执行文件。 通常有一个名为<AppName> 的可执行文件，它是应用程序的入口点。</li><li>Resources 文件夹:这个文件夹包含了应用程序所需的资源文件，例如图像、字体、帮助文档等。它还包含了 Python 解释器、标准库文件、动态链接库（.dylib文件）以及其他依赖库。</li><li>Frameworks 文件夹:如果应用程序使用了任何额外的框架，它们通常会被放置在这里。</li></ul><p>当运行一个使用 py2app 创建的 macOS应用程序时，以下是一般的运行流程：</p><p>当双击 .app 文件时，macOS 会启动 <AppName> 可执行文件，加载 Python解释器，加载应用程序代码，加载依赖库，运行应用程序。</p><p><strong>通过此方法打包并没有还是需要通过解释器解释，无法直接执行机器码。</strong></p><h2 id="打包时存在的bug">2. 打包时存在的Bug</h2><p>当执行python setup.py py2app -A，实现创建一个Alias Mode的app(AliasMode即app中不含有python解释器和相关的python包与相关的动态库，但是含有它们的alias，即快捷方式)时，没有任何问题。</p><p>但是当执行python setup.pypy2app，实现对一些python依赖的包进行打包时候，会存在可以成功创建app但是app无法正常运行的问题。打开Unix可执行文件，可以发现会报错： <figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs swift"><span class="hljs-type">ImportError</span>: dlopen(<span class="hljs-regexp">/Users/</span>yanwang<span class="hljs-regexp">/Desktop/</span><span class="hljs-type">AdaptHexo</span><span class="hljs-regexp">/dist/</span><span class="hljs-type">AdaptHexo</span>.app<span class="hljs-regexp">/Contents/</span><span class="hljs-type">Resources</span><span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">11</span><span class="hljs-regexp">/lib-dynload/</span>_tkinter.so, <span class="hljs-number">0x0002</span>): <span class="hljs-type">Library</span> not loaded: <span class="hljs-meta">@rpath</span><span class="hljs-operator">/</span>libtk8.<span class="hljs-number">6</span>.dylib<br>  <span class="hljs-type">Referenced</span> from: <span class="hljs-operator">&lt;</span><span class="hljs-type">D2E508CF</span><span class="hljs-operator">-</span>2AE0<span class="hljs-operator">-</span><span class="hljs-number">3E26</span><span class="hljs-operator">-</span>9ABA<span class="hljs-operator">-</span><span class="hljs-type">C5AAD3550B76</span><span class="hljs-operator">&gt;</span> <span class="hljs-regexp">/Users/</span>yanwang<span class="hljs-regexp">/Desktop/</span><span class="hljs-type">AdaptHexo</span><span class="hljs-regexp">/dist/</span><span class="hljs-type">AdaptHexo</span>.app<span class="hljs-regexp">/Contents/</span><span class="hljs-type">Resources</span><span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">11</span><span class="hljs-regexp">/lib-dynload/</span>_tkinter.so<br>  <span class="hljs-type">Reason</span>: tried: &#x27;<span class="hljs-regexp">/Users/</span>yanwang<span class="hljs-regexp">/Desktop/</span><span class="hljs-type">AdaptHexo</span><span class="hljs-regexp">/dist/</span><span class="hljs-type">AdaptHexo</span>.app<span class="hljs-regexp">/Contents/</span><span class="hljs-type">Resources</span><span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">11</span><span class="hljs-regexp">/lib-dynload/</span><span class="hljs-operator">../../</span>libtk8.<span class="hljs-number">6</span>.dylib&#x27; (no such file), &#x27;<span class="hljs-regexp">/Users/</span>yanwang<span class="hljs-regexp">/Desktop/</span><span class="hljs-type">AdaptHexo</span><span class="hljs-regexp">/dist/</span><span class="hljs-type">AdaptHexo</span>.app<span class="hljs-regexp">/Contents/</span><span class="hljs-type">Resources</span><span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">11</span><span class="hljs-regexp">/lib-dynload/</span><span class="hljs-operator">../../</span>libtk8.<span class="hljs-number">6</span>.dylib&#x27; (no such file), &#x27;<span class="hljs-regexp">/Users/</span>yanwang<span class="hljs-regexp">/Desktop/</span><span class="hljs-type">AdaptHexo</span><span class="hljs-regexp">/dist/</span><span class="hljs-type">AdaptHexo</span>.app<span class="hljs-regexp">/Contents/</span><span class="hljs-type">Frameworks</span><span class="hljs-regexp">/libtk8.6.dylib&#x27; (no such file), &#x27;/</span>usr<span class="hljs-regexp">/local/</span>lib<span class="hljs-regexp">/libtk8.6.dylib&#x27; (no such file), &#x27;/</span>usr<span class="hljs-regexp">/lib/</span>libtk8.<span class="hljs-number">6</span>.dylib&#x27; (no such file, not <span class="hljs-keyword">in</span> dyld cache)<br></code></pre></td></tr></table></figure>原因在于虽然这种方法会创建一个包含python解释器的app，但是部分动态库是不在app内部，是在内部的一个文档里面记录其绝对地址，而同一动态库绝对地址对于不同的电脑位置并不一样（比如Intel芯片的Macbook和Apple芯片的Macbook位置不一样），导致记录的动态库的绝对地址可能对于某一电脑是错误的。</p><p>若需要保证其在所有Apple芯片的电脑上均可使用，需要将动态库的地址修改为正确的地址（记录需要使用的动态库在Apple芯片的电脑上正确的绝对地址，或者将动态库放入app内部，记录动态库正确的相对地址）。</p>]]></content>
    
    
    <categories>
      
      <category>software engineering</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>图神经网络总结</title>
    <link href="/2024/08/08/Different%20Paradigms%20of%20Graph%20Neuron%20Network/Different%20Paradigms%20of%20Graph%20Neuron%20Network/"/>
    <url>/2024/08/08/Different%20Paradigms%20of%20Graph%20Neuron%20Network/Different%20Paradigms%20of%20Graph%20Neuron%20Network/</url>
    
    <content type="html"><![CDATA[<h1 id="graph-neuron-networks-gnns">1. Graph Neuron Networks (GNNs)</h1><p><strong>思路：</strong> 巴拿赫不动点理论 (Banach's Fixed PointTheory) 为模型提供了理论依据。</p><p><strong>模型架构：</strong> 其输入为一张用向量标注的无向图<spanclass="math inline">\(G=(V,E)\)</span>（每个结点和边均被提前embedding为<spanclass="math inline">\(d\)</span>维），进行多轮更新得到中间输出<spanclass="math inline">\(H^{output}\)</span>，中间输出<spanclass="math inline">\(h^{output}_v\)</span>为表示图中结点的相关隐含信息向量，最终输出<spanclass="math inline">\(O\)</span>为图中结点类别信息。 （从<spanclass="math inline">\(h^{output}_v\)</span>到<spanclass="math inline">\(o^v\)</span>可以先将<spanclass="math inline">\(h^{output}_v\)</span>和<spanclass="math inline">\(x_v\)</span>拼接，然后加全连接层输出类别概率再使用softmax，最后进行argmax操作）</p><p>模型更新次数并不是固定的，在每一轮更新中，此模型对所有结点进行以下操作（将前馈神经网络的输出相加）：<span class="math display">\[h^{t+1}_{v} = f(x_v, x_co[v], h^t_ne[v],x_ne[v])=\sum_{u\in ne[v]}FNN([x_v, x_{(u,v)},h^t_u,x_u]) \]</span>其中，<span class="math inline">\(h^{t+1}_{v}\)</span>表示结点<spanclass="math inline">\(v\)</span>在<spanclass="math inline">\(t+1\)</span>时刻的隐状态，<spanclass="math inline">\(x_v, x_co[v]\)</span>分别表示结点<spanclass="math inline">\(v\)</span>和与结点<spanclass="math inline">\(v\)</span>相连的点的输入embedding，<spanclass="math inline">\(h^t_ne[v]\)</span>表示结点<spanclass="math inline">\(v\)</span>相连的点在<spanclass="math inline">\(t\)</span>时刻的隐状态，<spanclass="math inline">\(x_ne[v]\)</span>表示与结点<spanclass="math inline">\(v\)</span>相连的边的输入embedding。</p><p>当<spanclass="math inline">\(||H^{t+1}||_2-||H^{t}||_2&lt;\epsilon\)</span>时，终止更新得到输出<spanclass="math inline">\(h^{output}_v=h^v_{t+1}\)</span> <imgsrc="IMG_B14C45EDF889-1.jpeg" style="width:70.0%" alt="GNNs" /></p><p><strong>Loss function and optimaization：</strong> 基于Banach's FixedPointTheory，可以提出有约束优化，然后通过拉格朗日乘数法转化为无约束优化。<span class="math display">\[J=Loss + \lambda \cdot max(||\frac{\partialFNN}{\partial \mathbf{h}}||-c, 0), c\in (0,1)\]</span></p><p>在优化器方面，因为模型存在“参数共享”，即所有的<spanclass="math inline">\(FNN\)</span>参数是相通的，所以需要使用Almeida-Pineda算法更新参数信息。（参数共享的原因即为了方便处理多样化结构的图，只需要它们的embedding维度一致即可）</p><p><strong>Shortcomings：</strong> - 存在oversommothing问题 -没有完全将边和结点分开，在全连接层中边和结点的地位是等价的 -此模型如果用于处理有向图，无法考虑图的边是入边还是出边，此模型对于某一特定结点，其入边和出边地位是等同的。</p><h1 id="section"></h1><h1 id="convolutional-graph-neuron-networks-convgnns">2. ConvolutionalGraph Neuron Networks (ConvGNNs)</h1><p><strong>思路：</strong>ConvGNNs本质上受启发与CV领域的对图像进行卷积操作。但是在某一定义下，图像的邻居较为规则，结合邻居结点的信息进行卷积操作也非常简单可行，然而Graphs却结构较为多样，所以需要对其进行修改，让其可以充分使用邻居结点的信息。</p><p><strong>模型架构：</strong>输入一张无向图的结点embedding信息和adjacency matrix，即<spanclass="math inline">\((H^{(0)},A)\)</span>，中间输出图中所有结点的状态向量，最后输出结点的类别or图的类别信息，其中<spanclass="math inline">\(H^{(0)}\)</span>的第<spanclass="math inline">\(i\)</span>行为结点<spanclass="math inline">\(i\)</span>的<spanclass="math inline">\(d\)</span>维embedding向量。</p><p>模型层数固定，每一层参数互不共享，第<spanclass="math inline">\(i+1\)</span>层计算方法如下： <spanclass="math display">\[H^{(i+1)}=f_{i+1}(H^{(i)},A)=\sigma\left(\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}H^{(i)}W^{(i)}\right)\]</span>- <spanclass="math inline">\(\hat{A}=A+I\)</span>,使得更新时考虑到自己在上一时刻的信息- <span class="math inline">\(\hat{D}\)</span>中除对角线上元素为<spanclass="math inline">\(\hat{A}\)</span>对应行的<spanclass="math inline">\(L1\)</span>范数，其余元素均为0，<spanclass="math inline">\(\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}\)</span>用于对表示相邻关系的矩阵进行symmetricnormalization (对称归一化)，使得all colums and rows的<spanclass="math inline">\(L1\)</span>范数为1 - <spanclass="math inline">\(\sigma\)</span>为激活函数，按位激活 - <spanclass="math inline">\(T=\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}H^{(i)}\)</span>即求结点相邻结点向量的平均值，<spanclass="math inline">\(T\)</span>的第<spanclass="math inline">\(i\)</span>行表示结点<spanclass="math inline">\(i\)</span>的相邻结点的隐状态向量与其自身的隐状态向量的加权平均值（其中各结点的权重即<spanclass="math inline">\(\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}\)</span>的第<spanclass="math inline">\(i\)</span>行） - <spanclass="math inline">\(TW^{(i)}\)</span>可看作“卷积”操作</p><figure><img src="o_image-10-gcn-framework.png" style="width:70.0%"alt="ConvGNNs" /><figcaption aria-hidden="true">ConvGNNs</figcaption></figure><p><strong>相关细节：</strong>在实际情况下，会使用类似于残差神经网络的结构，引入dropout，对Loss进行L2正则化处理,修改<span class="math inline">\(\hat{A}=A+\lambda I\)</span>等。</p><p><strong>Shortcomings：</strong> -此模型在每一层的计算中只考虑到了与其相邻的结点，没有考虑与其可达但不相邻的结点的信息，使其“感受野”受到一定的限制- 同GNN，如果用于处理有向图，无法充分使用有向图的入边出边信息。</p><h1 id="section-1"></h1><h1 id="recurrent-graph-neural-networks-recgnns">3. Recurrent GraphNeural Networks (RecGNNs)</h1><h2 id="gated-graph-neuron-networks-ggnns">(1) Gated Graph NeuronNetworks (GGNNs)</h2><p><strong>思路：</strong>GNN和ConvGNNs主要用于classification问题，在此基础上，GGNNs被提出，其对类似于LSTM的GRU模块进行改变并加入模型。（GRU可看作LSTM的一种优化，可以用于捕捉长距离的依赖关系，用于解决一些序列输出问题）</p><figure><img src="2381773f90e146868d4f6d0b4990813f.png" style="width:70.0%"alt="GRU模块" /><figcaption aria-hidden="true">GRU模块</figcaption></figure><p><strong>模型架构：</strong> 其输入为一张每一个结点均用<spanclass="math inline">\(d\)</span>维向量标注的有向图<spanclass="math inline">\(G=(V, E)\)</span>， 模型具有<spanclass="math inline">\(K\)</span>层，第一层即对所有结点如(1)初始化隐状态（<spanclass="math inline">\(v\)</span>表示结点编号），第二层以后每层类GRU模块数等于输入结点数，第<spanclass="math inline">\(t\)</span>层（<spanclass="math inline">\(t\)</span>大于1）的第<spanclass="math inline">\(v\)</span>个类GRU模块计算公式如(2)-(6)所示。</p><figure><img src="未命名-3.jpg" style="width:100.0%" alt="GGNNs计算公式" /><figcaption aria-hidden="true">GGNNs计算公式</figcaption></figure><p>其中<span class="math inline">\(A_v\)</span>是从<spanclass="math inline">\(A\)</span>中截取出来的两列组成的矩阵，截取outgoingedges的第<span class="math inline">\(v\)</span>列和incomingedges的第<span class="math inline">\(v\)</span>列。</p><p><img src="未命名-2.jpg" style="width:70.0%" alt="矩阵A的含义" />经过<span class="math inline">\(K\)</span>层得到<spanclass="math inline">\(H=[h^{(k)}_1; h^{(k)}_2;h^{(k)}_1;...h^{(k)}_{|{\mathcal{V}}|}]\)</span>，再经过一些输出层即可得到模型输出。</p><p><strong>特点：</strong> - 可以处理有向图 -使用GRU模块的变体，助于网络学习长期依赖关系 -类GRU模块参数也是共享的，本文使用Adam进行optimization</p><p><strong>另一个类似的模型：</strong>此模型可以用于处理与图有关的序列问题。 eg：输出两点间的最短路径序列但是感觉将如此复杂的模型用于如此简单的任务有小题大作之嫌 <imgsrc="未命名-5.jpg" style="width:90.0%"alt="GATED GRAPH SEQUENCE NEURAL NETWORKS" /></p><h1 id="section-2"></h1><h1 id="graph-autoencoders-gaes">4. Graph Autoencoders (GAEs)</h1><h2 id="basic-gaes">(1) Basic GAEs<a href="#fn1" class="footnote-ref"id="fnref1" role="doc-noteref"><sup>1</sup></a></h2><p><strong>思路：</strong>本模型源将图卷积神经网络与自编码模型相结合构造出可以用于图结点关系预测的模型。<img src="未命名2.jpg" style="width:70.0%"alt="Traditional Autoencoder Model" />传统的自编码模型如上图所示，输入<spanclass="math inline">\(X\)</span>，输出<spanclass="math inline">\(\hat{X}\)</span>，即对X的估计。此模型可以用于词嵌入，图像特征提取，图像降噪增强等方面。</p><p><strong>模型架构：</strong>此模型输入一张不完整的，可以添加link（无向边）的无向图<spanclass="math inline">\(G=(V, E)\)</span>，先得到图<spanclass="math inline">\(G\)</span>的结点embedding的<spanclass="math inline">\(N\times D\)</span>维矩阵<spanclass="math inline">\(X\)</span>与<span class="math inline">\(N\timesN\)</span>维邻接矩阵<span class="math inline">\(A\)</span>。</p><figure><img src="未命名-4.jpg" style="width:70.0%" alt="Basic GAEs" /><figcaption aria-hidden="true">Basic GAEs</figcaption></figure><p>然后进入encoder层（Paper中称为inferencemodel）进行两层ConvGNN后并采样得到中间的latent variable，即<spanclass="math inline">\(N\times D\)</span>维矩阵<spanclass="math inline">\(Z\)</span>，encoder层具体计算方法如下所示。</p><p><spanclass="math display">\[\widetilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\]</span>- ecoder第一层： <span class="math display">\[\bar{X}  =ConvGNN(X,A)=ReLU(\widetilde{A}XW_0)\]</span> - encoder第二层： <spanclass="math display">\[\mu =ConvGNN_\mu(\bar{X},A)=\widetilde{A}\bar{X}W_1\]</span> <spanclass="math display">\[log\sigma =ConvGNN_\sigma(\bar{X},A)=\widetilde{A}\bar{X}W_2\]</span> -encoder计算Z的分布并采样： <spanclass="math display">\[Z_{var}=\mu+\sigma * \epsilon\]</span> <spanclass="math display">\[\epsilon\sim N(0,1)\]</span> 即<spanclass="math inline">\(Z_{var}  \sim N(\mu, \sigma^2)\)</span>然后对随机变量矩阵<spanclass="math inline">\(Z_{var}\)</span>采样得到<spanclass="math inline">\(Z\)</span></p><p>最后通过decoder层（Paper中称为generative model）得到<spanclass="math inline">\(\hat{A}\)</span>，即补充完图中缺失的link后的邻接矩阵，，decoder层具体计算方法如下所示。<span class="math display">\[P(A_{ij}=1|{z_i}, {z_j}) = \sigma({z^T_iz_j})\]</span> 然后再通过特定的阈值推断<spanclass="math inline">\(A_{ij}\)</span>的值。</p><p><strong>相关细节：</strong> -本文中应用KL散度于损失函数中，但目前对损失函数的理论依据不太了解 -本文中化器用Adam ## (2) GAEs for network embedding ## (3) GAEs for graphgeneration</p><h1 id="section-3"></h1><h1 id="spatial-temporal-graph-neural-networks-stgnns">5.Spatial-Temporal Graph Neural Networks (STGNNs)</h1><section id="footnotes" class="footnotes footnotes-end-of-document"role="doc-endnotes"><hr /><ol><liid="fn1"><p>https://towardsdatascience.com/tutorial-on-variational-graph-auto-encoders-da9333281129<ahref="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>图神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Event-Event Relation Extraction</title>
    <link href="/2024/08/08/Event-Event%20Relation%20Extraction/Event-Event%20Relation%20Extraction/"/>
    <url>/2024/08/08/Event-Event%20Relation%20Extraction/Event-Event%20Relation%20Extraction/</url>
    
    <content type="html"><![CDATA[<h1 id="event-event-relation-extraction">Event-Event RelationExtraction</h1><h3 id="related-definitions">1. Related Definitions</h3><ol type="1"><li><p><strong>事件：</strong> An event is an occurrence of societalimportance, typically happening at a specific time and location,involving a set of participants. It can be represented as <spanclass="math inline">\((action\; or \;status, persons, time,location)\)</span>, action or status can be also called as a<strong>trigger word</strong>. Besides, in a graph, a node with a tagwritten its trigger word and with other subsidiary information nodesconnected can represent a event briefly. <imgsrc="Event%20in%20Graph.jpg" alt="Event in Graph" /></p></li><li><p><strong>事件关系抽取：</strong>即抽取事件之间的关系，事件之间的关系包括但不限于因果关系(CasualRelation)，子事件关系(Subevent Relation)，时序关系(TemporalRelation)，等同关系等，这些关系大类里又可以细分为诸多子关系。比如，时序关系可以分为before，after和overlapping等子关系。</p></li><li><p><strong>事件因果关系抽取：</strong>即抽取事件之间的因果关系(Casual Relation)，因果关系也可以细分为explicitcasualty和implicit casualty等子关系。</p></li></ol><h3 id="事件抽取与事件关系抽取的相关工作">2.事件抽取与事件关系抽取的相关工作</h3><ul><li><p><strong>GraphERE</strong> <img src="GraphERE.jpg"style="width:80.0%" alt="GraphERE" />此模型可以用于抽取文本中的一系列events及其关系，首先，包含多个events的文本被输入，然后相应的解析器解析成两种不同的Graphs(AMR andIE)，再对每一个事件进行增强嵌入得到event向量，最后通过transformer和DeepGraph Learning获得关系抽取结果图。</p></li><li><p><strong>GraphIE</strong>可以给定一句包含事件的语句作为模型输入，模型通过decoder输出各个token的tag，即：某词是事件的触发词，某词是事件的论元…然后就可以使用这些知识构建图。 <img src="GraphIE.jpg"style="width:80.0%" alt="GraphIE" /></p></li><li><p><strong>ERNIE</strong>ERNIE是一种新的预训练模型，可看作Transformer的decoder架构的一种变体，可以结合大规模文本语料库和知识图谱(KGs)，利用知识图谱中丰富的结构化知识事实来增强预训练模型的语言理解能力。<img src="未命名.jpg" style="width:80.0%" alt="ERNIE" />如图所示，此模型用于输入一段文本与文本中输入文本中某一些tokens对应的entities，输出一段文本与entity对应的输入tokens的位置，输出的文本可以是对输入mask的推测，对输入的下一句话的预测等。实验也证明它比BERT等baseline模型效果要好。</p></li><li><p><strong>Prompt-based event relation identification withConstrained Prefix Attention mechanism</strong>本文提出了一种新的事件关系抽取框架，输入两个分别包含1个event的语句，系统即可判断出两个event之间的并且属于<spanclass="math inline">\(relation\;set=[casual, \;temporal,\;unrelated]\)</span> 的关系。 <img src="11.jpg"alt="Prompt Based Model" />在创新点方面，本文主要提出了两点改进：</p></li></ul><ol type="1"><li>在输入中添加包含一系列关系名称的 <spanclass="math inline">\(prefix=relation\;set\)</span>，并在BART模型中添加prefix-biased fully-connectedattention层，让关系对应的attentionbias可以体现在每一个输入的token中。</li><li>Inspired by ZLPR，作者提出了一种特别的损失函数，可以考虑中间过程并且更加关注正确的prefix。除此以外，交叉熵损失函数也被作为最终损失函数的一部分。</li></ol><ul><li><strong>MetaIE</strong></li></ul><ol type="1"><li>此模型可以输入一段文本，输出序列标注和spans。</li><li>此模型思路相对较为简单，即通过Symbolic KnowledgeDistillation将参数量大的Teacher Model变为Student Model。</li><li>此模型使用的Teacher Model是GPT-3.5-turbo via LLM Prompting within-context learning，Student Model是RoBERTa-Large。</li><li>在构建训练集时，本文使用大语言模型对海量的数据进行提问整合，减小了构建数据集的难度。</li><li>虽然此方法能够通过大模型训练出效果较好的小模型，但是，此方法也会将大模型的bias带入小模型。</li></ol><p><img src="MetaIE.jpg" alt="MetaIE" /> - <strong>Selecting OptimalContext Sentences for Event-Event Relation Extraction</strong>此模型可以输入一段document并标注出event的触发词语，输出event之间的关系。在创新方面，此模型主要抓住大语言模型无法理解长文本这一问题作出改进，提取出输入的文本中不包含triggerword的但是与事件关系有关的语句作为关键语句，将关键语句和包含triggerword的语句整合送入大语言模型得到抽取结果。</p><ul><li><strong>Mastering Context-to-Label Representation Transformation forEvent Causality Identification with Diffusion Models</strong>此模型可以输入两句描述event的语句，输出它们之间的关系。此模型受启发于CV领域的diffusionmodel(先添加高斯噪声，后逆向还原图像)，训练出一个可以将文本中的“噪声”（不相关文本）剔除的模型。<img src="Diffusion%20Model.jpg" alt="Diffusion Model" /></li></ul><h3 id="summary">3. Summary</h3><ol type="1"><li><strong>任务形式差别</strong>在任务形式方面，有些是给定了带有event的语句要求抽取出其关系；有些是给定一段文本，要求先抽取出event后找出其关系。</li><li><strong>方法差别</strong>在实现方法方面，一般是将对话大语言模型，预训练模型(PLM)，知识图谱，提示工程中的几个内容相结合成新的模型实现。</li></ol><h3 id="current-challenges">4. Current Challenges</h3><ol type="1"><li>因果关系中的explicit casualty相对较容易提取，但是implicitcasualty因为没有明确的关键词提示较难提取。</li><li>目前模型需要大规模的训练集进行训练，然而目前训练集规模普遍偏小。eg:the largest existing dataset Event Story Line only contains 258documents, and the training data in practical application scenarios isscarcer than Event Story Line.</li><li>目前以大语言模（如GhatGPT）为基础的事件及其关系抽取模型存在bias与hallucination（大模型幻觉），并且在模型中添加InContext Learning或者Chain ofThoughts后会加剧hallucination这一现象。除此以外，大模型对提问的prompt非常敏感，很难调整到合适的prompt并且缺乏理论依据。</li><li>可能输入语句中存在大量不相关的内容导致大量noise产生，从而影响模型效果。</li><li>有一些事件使用过长的语句描述并且其关系也要结合长上下文进行理解，然而目前大语言模型对长上下文的理解能力有限，比如BERT模型的输入最长只有512个token。</li><li>有一些文本中两个事件的触发词语之间的distance较长，即两个触发词之间相隔的token数较多，模型难以抽取之间的关系。</li><li>对于一些zero-shot的问题无法得到较好的抽取结果</li></ol>]]></content>
    
    
    <categories>
      
      <category>事件关系抽取</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Advanced Paradigm of GNN</title>
    <link href="/2024/08/08/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/"/>
    <url>/2024/08/08/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/</url>
    
    <content type="html"><![CDATA[<h1 id="section"></h1><ul><li><p><strong>Meta-Path</strong>元路径（Meta-Path）是图数据挖掘和分析中的一个重要概念，尤其是在异构信息网络（HeterogeneousInformation Network,HIN）中应用广泛。元路径可以理解为在异构信息网络中连接不同类型节点的一条路径，这条路径按照特定的节点类型和边类型顺序排列。</p></li><li><p><strong>Heterogeneous Graph</strong>异质图指具有不同类型的结点或者边的图，若其具有不同类型的边，其可看作多片同质图的叠加。# ## 1. GTN (Graph Transformer Network) <img src="GTNs.jpg"alt="GTNs.jpg" /></p></li></ul><p>整个模型架构可以看成是：在由GraphTransformer层学习到的多片元路径图（meta-pathgraphs）上进行GCN。可以用于异质图分类，异质图结点分类，异质图边链接预测等任务。</p><p><strong>Advantages</strong> 1.传统的GNN将所有的边都视作同一种类型，而GT层的引入可以使得模型能够较好地学习不同类型的异质边的特点并将其转化为元路径（同质边）供GNN进行操作。2. 因为模型会对输入的权重和矩阵添加identifymatrix，所以模型可以学习到变长的元路径权重和矩阵（最大长度为GT层的层数+1，最小长度为0），以更好地用于下游任务。消融性实验也证明学习变长路径的重要性。3.除此以外，实验也证明GT学习出的元路径（无需预定义元路径）可以非常好地对学习nodesrepresentation.</p><p><strong>Shortcomings</strong> 1.本方法虽然名为GT，但是GT中的每一层没有体现出transformer中的self-attention机制（使用Query，Key和Vector），只有简单的attention机制。可以结合自注意力，通过图的结构得到卷积核。2. 本方法GT层只有卷积，可以加入池化层 (Graph Level Pooling)对重要特征进行提取。 # - <strong>Weisfeiler-Lehamn Test</strong>用于判断两个图是否可能同构，当某一次迭代更新标签后两个图相同的标签出现的次数不一致，则两个图不可能同构（不同构）。<img src="20191219161502970.png" alt="20191219161502970.png" /> <imgsrc="WLtest流程1-4.png" alt="WLtest流程1-4.png" /></p><h1 id="section-1"></h1><h2 id="gin-graph-isomorphism-network">2. GIN (Graph IsomorphismNetwork)</h2><p>在本文中，作者提出GCN可以看作WL-test的一种变形，当GCN的聚合函数满足一定条件，其表征能力与WL-test相同。（但是现有GCN达不到）在此基础上，作者提出GIN，即一种可以逼近WL-test的GNN。</p>]]></content>
    
    
    <categories>
      
      <category>图神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Event-Event Relation Extraction Datasets</title>
    <link href="/2024/07/31/event-to-event-relation-extraction-dataset/"/>
    <url>/2024/07/31/event-to-event-relation-extraction-dataset/</url>
    
    <content type="html"><![CDATA[<h1 id="event-event-relation-extraction-datasets">Event-Event RelationExtraction Datasets</h1><h2 id="maven-ere">1. <ahref="https://github.com/THU-KEG/MAVEN-ERE">MAVEN-ERE</a> 🤩🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://arxiv.org/pdf/2211.07342">https://arxiv.org/pdf/2211.07342</a></p><p><strong>Data Distribution:</strong> - 4,480 documents - 168fine-grained event types - 112,276 mentions - 103,193 event coreferencechains - 1,216,217 temporal relations (BEFORE, OVERLAP, CONTAINS,SIMULTANEOUS, BEGINS-ON, ENDS-ON) - 15,841 subevent relations - 57,992causal relations (CAUSE, PRECONDITION)</p><p><strong>Data Format:</strong> <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;f28bce270df5a122c09365002d247e76&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for each document</span><br>  <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;United States occupation of Nicaragua&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the tiltle of the document</span><br>  <span class="hljs-attr">&quot;tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for tokenized document content. each item is a tokenized sentence</span><br>    <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;The&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;United&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;States&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;occupation&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;of&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Nicaragua&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;from&quot;</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-string">&quot;1912&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;to&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;1933&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;was&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;part&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;of&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;the&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Banana&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Wars&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;,&quot;</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-string">&quot;when&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;the&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;US&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;military&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;intervened&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;in&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;various&quot;</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-string">&quot;Latin&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;American&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;countries&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;from&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;1898&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;to&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;1934&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;.&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;sentences&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// untokenized sentences of the document. each item is a sentence (string)</span><br>      <span class="hljs-string">&quot;The United States occupation of Nicaragua from 1912 to 1933 was part of the Banana Wars, when the US military intervened in various Latin American countries from 1898 to 1934.&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;events&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for annotated events, each item is a dict for an event (coreference chain)</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;EVENT_0341c5cced5545ffe7c543b7a155bfa8&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for the event (coreference chain)</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Choosing&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the event type</span><br>            <span class="hljs-attr">&quot;type_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">25</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the numerical id for the event type, consistent with MAVEN</span><br>            <span class="hljs-attr">&quot;mention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for the coreferential event mentions of the chain, each item is a dict. they have coreference relations to each other</span><br>                <span class="hljs-punctuation">&#123;</span><br>                    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;a75ba55cadad23555a0ffc9454088687&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for the event mention</span><br>                    <span class="hljs-attr">&quot;trigger_word&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assumed&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// a string of the trigger word or phrase</span><br>                    <span class="hljs-attr">&quot;sent_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the index of the corresponding sentence, starts with 0</span><br>                    <span class="hljs-attr">&quot;offset&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// the offset of the trigger words in the tokens list</span><br>                <span class="hljs-punctuation">&#125;</span><br>            <span class="hljs-punctuation">]</span><br>        <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;TIMEX&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for annotated temporal expressions (TIMEX), each item is a dict for a TIMEX</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TIME_833e41f3304210094101eca59905055e&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for the TIMEX</span><br>      <span class="hljs-attr">&quot;mention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1912&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// a string of the mention of the TIMEX</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;DATE&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the type of the TIMEX</span><br>      <span class="hljs-attr">&quot;sent_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the index of the corresponding sentence, starts with 0</span><br>      <span class="hljs-attr">&quot;offset&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">7</span><span class="hljs-punctuation">,</span> <span class="hljs-number">8</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// the offset of the trigger words in the tokens list</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;temporal_relations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-comment">// a list for annotated temporal relations between events (and TIMEXs)</span><br>    <span class="hljs-attr">&quot;BEFORE&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for temporal relations of BEFORE type</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TIME_id_2&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// a temporal relation instance, means EVENT_id_1 BEFORE TIME_id_2</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;OVERLAP&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// all the following types are similar</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;CONTAINS&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;SIMULTANEOUS&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;ENDS-ON&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;BEGINS-ON&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;causal_relations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-comment">// a list for annotated causal relations between events</span><br>    <span class="hljs-attr">&quot;CAUSE&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>  <span class="hljs-comment">// a list for causal relations of CAUSE type</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// a causal relation instance, means EVENT_id_1 CAUSE EVENT_id_2</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;PRECONDITION&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// the PRECONDITION type is similar</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;subevent_relations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for annotated subevent relations between events</span><br>    <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// a subevent relation instance, means EVENT_id_2 is a subevent of EVENT_id_1</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></p><h2 id="choice-of-plausible-alternatives-copa">2.<ahref="https://asgordon.github.io/copa.html">Choice of PlausibleAlternatives (COPA)</a></h2><p><strong>Paper:</strong> <ahref="https://asgordon.github.io/publications/AAAI-SPRING11A.PDF">https://asgordon.github.io/publications/AAAI-SPRING11A.PDF</a></p><p><strong>Data Distribution:</strong> - 1000 groups - each group has 2relations, one is correct and the other is false. - only 2 types ofrelation (cause, effect)</p><p><strong>Data Format:</strong> <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">item</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;3&quot;</span> <span class="hljs-attr">asks-for</span>=<span class="hljs-string">&quot;cause&quot;</span> <span class="hljs-attr">most-plausible-alternative</span>=<span class="hljs-string">&quot;2&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>The women met for coffee.<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">a1</span>&gt;</span>The cafe reopened in a new location.<span class="hljs-tag">&lt;/<span class="hljs-name">a1</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">a2</span>&gt;</span>They wanted to catch up with each other.<span class="hljs-tag">&lt;/<span class="hljs-name">a2</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">item</span>&gt;</span><br></code></pre></td></tr></table></figure></p><h2 id="e-care">3. <ahref="https://github.com/Waste-Wood/e-CARE?tab=readme-ov-file">e-CARE</a></h2><p><strong>Paper:</strong> <ahref="https://arxiv.org/pdf/2205.05849">https://arxiv.org/pdf/2205.05849</a></p><p><strong>Data Distribution:</strong> - 21,324 groups (7,617 groups ofcause relation and 7,311 groups of effect relation) - each group has 2relations (one is correct and the other is false) and a explanation.</p><p><strong>Data Format:</strong> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs jsonl">&#123;&quot;index&quot;: &quot;train-0&quot;, <br>&quot;premise&quot;: &quot;There is a light rain today.&quot;, <br>&quot;ask-for&quot;: &quot;effect&quot;, <br>&quot;hypothesis1&quot;: &quot;The roots of many plants are not moistened by rain.&quot;, <br>&quot;hypothesis2&quot;: &quot;Tourists have seen many ripples.&quot;, <br>&quot;label&quot;: 0&#125;<br><br>&#123;&quot;index&quot;: &quot;train-0&quot;, <br>&quot;cause&quot;: &quot;There is a light rain today.&quot;, <br>&quot;effect&quot;: &quot;The roots of many plants are not moistened by rain.&quot;, <br>&quot;conceptual_explanation&quot;: &quot;Precipitation reaches soil surfaces.&quot;&#125;<br></code></pre></td></tr></table></figure></p><h2 id="esl">4. <ahref="https://github.com/tommasoc80/EventStoryLine?tab=readme-ov-file">ESL</a>🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/W17-2711.pdf">https://aclanthology.org/W17-2711.pdf</a></p><p><strong>Data Distribution:</strong> - 258 documents with 22 topics -7,275 event mentions - three types of relations (Temporal, Co-Reference,Plot) - Temporal relation can be divided into contains, before, afterand overlap.</p><h2 id="ctb">5. <ahref="https://github.com/paramitamirza/Causal-TimeBank">CTB</a>🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/W14-0702.pdf">https://aclanthology.org/W14-0702.pdf</a></p><p><strong>Data Distribution:</strong> - 6,811 EVENTs (only instantiatedevents by MAKEINSTANCE tag of TimeML) - 5,118 TLINKs (temporal links) -171 CSIGNALs (causal signals) - 318 CLINKs (causal links)</p><h2 id="meci">6. <ahref="https://github.com/nlp-uoregon/meci-dataset">MECI</a> 🤩🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/2022.coling-1.206.pdf">https://aclanthology.org/2022.coling-1.206.pdf</a></p><p><strong>Data Distribution:</strong> - 5 languages, 5 topics, morethan 1,000 articles per topic for each language - the annotation methodis same as ESL</p><p><strong>Data Format:</strong> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs tsvx">TextThe policy document sets out what must be done to deliver a global response &quot; that leaves no - one behind &quot; , reduces global vulnerability to future pandemics , builds resilience to future shocks , especially climate change , and addresses &quot; the severe and systemic inequalities exposed by the pandemic &quot; .The document focuses on three main operational approaches , namely delivering a large coordinated and comprehensive response on health ; adopting policies to address the adverse human rights , humanitarian , and socioeconomic , humanitarian effects ; and creating a recovery process that &quot; builds back better &quot; .As part of the United Nations &#x27; response , the UN Secretary - General has been prominent in ensuring the maintenance of normal UN operations , in launching events , and making in appeals on behalf of the United Nations System , including for the world &#x27;s first global ceasefire and for billions of dollars in funding .He has also defended the WHO &#x27;s response to the crisis and fought back against COVID - 19 misinformation .As the UN &#x27;s response became more systematized , he been issuing policy briefs , by theme , population , and region , to aid governments in how to address the consequences of the pandemic .<br><br>EventT0doneEVENT42<br>EventT1deliverEVENT50<br>EventT10pandemicEVENT294<br>EventT11focusesEVENT320<br><br>RelationT4T29CauseEffecttruereducessets out<br>RelationT29T4EffectCausetruesets outreduces<br>RelationT9T21NoReltrueexposedfought<br>RelationT9T3NoReltrueexposedleaves<br></code></pre></td></tr></table></figure></p><h2 id="hieve">7. <ahref="http://takelab.fer.hr/hievents.rar">HiEve</a></h2><h5 id="没有找到数据集">没有找到数据集</h5><p><strong>Paper:</strong> <ahref="http://www.lrec-conf.org/proceedings/lrec2014/pdf/1023_Paper.pdf">http://www.lrec-conf.org/proceedings/lrec2014/pdf/1023_Paper.pdf</a></p><h2 id="matres">8. MATRES</h2><p><strong>Paper:</strong> <ahref="https://arxiv.org/pdf/1804.07828">https://arxiv.org/pdf/1804.07828</a></p><p><strong>Data Format:</strong> <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs txt">WSJ_20130322_159apologizedhappened15VAGUE<br>WSJ_20130322_159apologizedwrapped16BEFORE<br>WSJ_20130322_159apologizedseemed110BEFORE<br></code></pre></td></tr></table></figure></p><h2 id="tddiscourse">9. <ahref="https://github.com/aakanksha19/TDDiscourse">TDDiscourse</a>🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/W19-5929.pdf">https://aclanthology.org/W19-5929.pdf</a></p><p><strong>Data Distribution:</strong> - Expand from TimeBank (containsmore temopral links), contains 6,150 relation pairs in TDD-Man and about38,000 relation pairs in TDD-Auto - it contains more long distiancerelation mentions (很多数据集只标注近距离的trigger words之间的关系) -relations include after, before, simultaneous, include andis-included</p><p><strong>Data Format:</strong> <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs txt">APW19980227.0468e1e8ii<br>APW19980227.0468e1e9ii<br>APW19980227.0468e1e10a<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>datasets</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>归一化(Normalization)的一些方法</title>
    <link href="/2024/07/24/%E5%85%B3%E4%BA%8E%E5%BD%92%E4%B8%80%E5%8C%96%20(Normalization)/"/>
    <url>/2024/07/24/%E5%85%B3%E4%BA%8E%E5%BD%92%E4%B8%80%E5%8C%96%20(Normalization)/</url>
    
    <content type="html"><![CDATA[<h1 id="行归一化">行归一化</h1><h2 id="矩阵行l1范数-or-矩阵行l2范数为1">(矩阵行L1范数 or矩阵行L2范数为1)</h2><ol type="1"><li><p><strong>计算行范数</strong>：首先计算原矩阵每一行的<spanclass="math inline">\(L_2\)</span>范数。</p></li><li><p><strong>创建范数矩阵</strong>：将这些范值构成一个对角矩阵<spanclass="math inline">\(D\)</span>，其中对角线上的元素是原矩阵的行范数，非对角线上的元素是0。</p></li><li><p><strong>逆范数矩阵</strong>：计算对角矩阵<spanclass="math inline">\(D\)</span>的逆矩阵<spanclass="math inline">\(D^{-1}\)</span>，其对角线上的元素是对应行范数的倒数。</p></li><li><p><strong>矩阵相乘</strong>：将原矩阵<spanclass="math inline">\(M\)</span>与逆范数矩阵<spanclass="math inline">\(D^{-1}\)</span>相乘，得到归一化后的矩阵<spanclass="math inline">\(M_{\text{norm}}\)</span>。</p></li></ol><p>数学上，如果<span class="math inline">\(M\)</span>是原始矩阵，<spanclass="math inline">\(D\)</span>是行范数构成的对角矩阵，那么归一化后的矩阵<spanclass="math inline">\(M_{\text{norm}}\)</span>可以通过以下公式计算：<span class="math display">\[M_{\text{norm}} = M \cdotD^{-1}\]</span></p><h1 id="对称归一化">对称归一化</h1><h2id="矩阵行与列l1范数均为1-or-矩阵行与列l2范数均为1">(矩阵行与列L1范数均为1or 矩阵行与列L2范数均为1)</h2><p><span class="math inline">\(D^{-1/2} AD^{-1/2}\)</span>这种归一化方法通常被称为对称归一化（symmetricnormalization）或双归一化（doublenormalization），它在数学和机器学习领域中有着特定的应用和效果。下面是这种归一化方法的详细说明和效果：</p><h3 id="归一化过程">归一化过程：</h3><ol type="1"><li><p><strong>构建对角矩阵<spanclass="math inline">\(D\)</span></strong>：首先，计算矩阵<spanclass="math inline">\(A\)</span>的行<spanclass="math inline">\(L_2\)</span>范数，用这些范数构建对角矩阵$D)。</p></li><li><p><strong>计算<spanclass="math inline">\(D^{-1/2}\)</span></strong>：接着，计算<spanclass="math inline">\(D\)</span>的逆矩阵的平方根，即<spanclass="math inline">\(D^{-1/2}\)</span>。这个操作将每个行范数取倒数再开平方。</p></li><li><p><strong>归一化操作</strong>：通过矩阵乘法<spanclass="math inline">\(D^{-1/2} A D^{-1/2}\)</span>对<spanclass="math inline">\(A\)</span>进行操作。</p></li></ol><h3 id="达到的效果">达到的效果：</h3><ol type="1"><li><p><strong>行和列的<spanclass="math inline">\(L_2\)</span>范数归一化</strong>：归一化后的矩阵<spanclass="math inline">\(A\)</span>中，每一行和每一列的<spanclass="math inline">\(L_2\)</span>范数都被缩放至1。这意味着矩阵<spanclass="math inline">\(A\)</span>中的每个向量（行和列）都变成了单位向量。</p></li><li><p><strong>数值稳定性</strong>：这种归一化可以提高数值计算的稳定性，因为它减少了由于某些行或列具有较大数值而导致的数值问题。</p></li><li><p><strong>特征值和奇异值的缩放</strong>：归一化后的矩阵<spanclass="math inline">\(A\)</span>的特征值和奇异值通常会被缩放至更小的范围，这有助于某些算法的性能和数值稳定性。</p></li><li><p><strong>数据预处理</strong>：在机器学习和数据分析中，这种归一化可以作为数据预处理的步骤，确保不同的特征具有相同的尺度，有助于算法的收敛和性能。</p></li><li><p><strong>对称性保持</strong>：如果矩阵<spanclass="math inline">\(A\)</span>是对称的，这种归一化方法保持了矩阵的对称性。</p></li><li><p><strong>改善条件数</strong>：通过缩放行和列，可以改善矩阵<spanclass="math inline">\(A\)</span>的条件数，即最大奇异值与最小奇异值的比率。一个较小的条件数意味着矩阵更接近于正交矩阵，数值解法更稳定。</p></li><li><p><strong>在谱聚类中的应用</strong>：在谱聚类算法中，这种归一化方法常用于预处理相似性矩阵或拉普拉斯矩阵，以提高算法的效率和效果。</p></li></ol><h3 id="数学解释">数学解释：</h3><p>归一化操作<span class="math inline">\(D^{-1/2} AD^{-1/2}\)</span>等价于先将<spanclass="math inline">\(A\)</span>的每一行通过<spanclass="math inline">\(D^{-1/2}\)</span>进行缩放，使得它们成为单位向量，然后对每一列也进行相同的操作。数学上，这可以表示为：</p><p><span class="math display">\[D^{-1/2} A D^{-1/2} = \left( D^{-1/2}A^T D^{-1/2} \right)^T\]</span></p><p>这意味着操作是对称的，即先对行操作再对列操作，或者先对列操作再对行操作，结果是相同的。</p><p>这种归一化方法在理论和实际应用中都很有用，特别是在需要处理矩阵特性（如特征值、奇异值、条件数）的算法中。</p>]]></content>
    
    
    <categories>
      
      <category>Basics Theory</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据归一化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Instruction of Deploy a Blog through Github Pages and Hexo</title>
    <link href="/2024/06/12/Instruction/Instruction/"/>
    <url>/2024/06/12/Instruction/Instruction/</url>
    
    <content type="html"><![CDATA[<h1id="instruction-of-deploy-a-blog-through-github-pages-and-hexo">Instructionof Deploy a Blog through Github Pages and Hexo</h1><p>This is an instruction of deploy a blog through Github Pages andHexo. Check <a href="https://hexo.io/docs/">documentation</a> for moreinfo.</p><h2 id="一初始化github-pages">一、初始化Github Pages</h2><h3 id="一目标">（一）目标</h3><p>部署带有一篇博客的个人博客网站，并且可以统计每一篇博客和整个网站的浏览量和浏览人数。</p><h3 id="二实现方法">（二）实现方法</h3><h3 id="注册个人github账号在自己电脑上安装git和nodejs">1. 注册个人<ahref="https://github.com/">Github账号</a>，在自己电脑上安装<ahref="https://git-scm.com/downloads">Git</a>和<ahref="https://nodejs.org/en">NodeJS</a></h3><p>NodeJS直接点击链接在网页里面找到LTS版本的符合自己电脑的安装包下载安装即可</p><h3 id="在github中创建一个公有仓库仓库名为.github.io">2.在Github中创建一个公有仓库，仓库名为<用户名>.github.io</h3><h3 id="安装hexo并初始化">3. 安装Hexo并初始化</h3><ul><li><p>在bash shell或者zsh shell中输入如下内容完成Hexo安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo npm install -g hexo-cli<br></code></pre></td></tr></table></figure></p></li><li><p>待显示安装完成后，输入如下内容查看版本，检查是否正确安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo npm install -g hexo-cli<br></code></pre></td></tr></table></figure></p></li><li><p>在shell中转到用于存储Hexo项目的文件夹，输入如下内容创建一个新Hexo项目<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo init blog<br><span class="hljs-built_in">cd</span> blog<br>npm install<br></code></pre></td></tr></table></figure></p></li><li><p>在shell中输入如下内容，在本地生成相关静态文件(hexo g)并启动(hexos)，通过浏览器访问浏览器访问 <ahref="http://localhost:4000">http://localhost:4000</a> 查看效果<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure></p></li><li><p>如果看到如下图片则说明部署成功</p><center><p><img src="hexo_init.jpg" alt="初始化后界面示意图" width="80%"/></p></center></li></ul><h3 id="更换fluid主题并配置相关字段使界面更加美观实用">4.更换Fluid主题，并配置相关字段，使界面更加美观实用</h3><ul><li><p>通过此网址<ahref="https://github.com/fluid-dev/hexo-theme-fluid">https://github.com/fluid-dev/hexo-theme-fluid</a>下载Fluid主题并将文件夹重命名为fluid，存放于blog/themes文件夹中</p></li><li><p>打开blog/_config.yml配置文件，修改theme，language和title等字段<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">theme:</span> fluid <span class="hljs-meta"># 一定要改</span><br><span class="hljs-symbol">post_asset_folder:</span> true <span class="hljs-meta"># 一定要改，方面后期发布修改博客文章  </span><br><span class="hljs-symbol">language:</span> <span class="hljs-built_in">zh</span>-CN <span class="hljs-meta"># 酌情选择（决定导航栏的显示语言）</span><br><span class="hljs-symbol">title:</span> a blog <span class="hljs-meta"># 酌情设置（决定浏览器tab的显示内容）</span><br></code></pre></td></tr></table></figure></p></li><li><p>与上操作类似，打开blog/thems/fluid/_config.yml配置文件，修改blog_title，text等字段</p></li><li><p>在shell中输入如下代码，在Blog中添加About页面<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haxe">hexo <span class="hljs-keyword">new</span> <span class="hljs-type">page</span> about<br></code></pre></td></tr></table></figure></p></li><li><p>之后可以在blog/source/about/index.md中修改文件调整页面内容</p></li><li><p>再次在shell中输入如下内容，通过浏览器访问浏览器访问 <ahref="http://localhost:4000">http://localhost:4000</a>查看更换主题后的效果 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure></p></li></ul><h3 id="设置阅读量统计">5. 设置阅读量统计</h3><ul><li><p>进入<ahref="https://console.leancloud.cn/">LeanCloud官网</a>注册账号，实名认证并验证邮箱</p></li><li><p>如下图所示创建应用</p><center><p><img src="leancloud-1.jpg" alt="创建应用" width="80%"/></p></center></li><li><p>如下图所示，进入设置-应用凭证，记录AppID，AppKey和REST API服多器地址</p><center><p><img src="leancloud-2.jpg" alt="id and key" width="80%"/></p></center></li><li><p>如下图所示，创建类用于存储访问数据，类名必须严格按照图片中的类名设置</p><center><p><img src="leancloud-3.jpg" alt="id and key" width="80%"/></p></center></li><li><p>打开blog/thems/fluid/_config.yml配置文件,修改如下内容<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># 一定要改</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">web_analytics:</span><br><span class="hljs-symbol">  enable:</span> true <br><span class="hljs-symbol"></span><br><span class="hljs-symbol">leancloud:</span><br><span class="hljs-symbol">    app_id:</span> <span class="hljs-params">&lt;AppID&gt;</span><br><span class="hljs-symbol">    app_key:</span> <span class="hljs-params">&lt;AppKey&gt;</span><br><span class="hljs-symbol">    server_url:</span> <span class="hljs-params">&lt;REST API 服多器地址&gt;</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">views:</span><br><span class="hljs-symbol">      enable:</span> true<br><span class="hljs-symbol">      source:</span> <span class="hljs-string">&quot;leancloud&quot;</span><br><span class="hljs-symbol">      format:</span> <span class="hljs-string">&quot;&#123;&#125; 次&quot;</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">statistics:</span><br><span class="hljs-symbol">    enable:</span> true<br><span class="hljs-symbol">    source:</span> <span class="hljs-string">&quot;leancloud&quot;</span><br><span class="hljs-symbol">    pv_format:</span> <span class="hljs-string">&quot;总访问量 &#123;&#125; 次&quot;</span><br><span class="hljs-symbol">    uv_format:</span> <span class="hljs-string">&quot;总访客数 &#123;&#125; 人&quot;</span><br></code></pre></td></tr></table></figure></p></li><li><p>再次在shell中输入如下内容，通过浏览器访问浏览器访问 <ahref="http://localhost:4000">http://localhost:4000</a>查看是否在页面下方显示访问情况 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure></p><center><p><img src="info.jpg" alt="info" width="80%"/></p></center></li></ul><h3 id="设置latex公式">6. 设置latex公式</h3><p>详见 <ahref="https://fluid-dev.github.io/hexo-fluid-docs/guide/#latex-数学公式">https://fluid-dev.github.io/hexo-fluid-docs/guide/#latex-数学公式</a></p><h3 id="上传至github">7. 上传至Github</h3><ul><li><p>安装hexo-deployer-git <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure></p></li><li><p>如图所示，获得Personal accesstokens，并注意在获得tokens时要选择Tokens(classic)并勾选repo</p></li><li><p>打开blog/_config.yml配置文件,设置部署参数 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">deploy:<br>  <span class="hljs-built_in">type</span>: git<br>  repo: https://&lt;你的Personal access tokens&gt;@github.com/&lt;你的Github用户名&gt;/&lt;你的Github用户名&gt;.github.io.git<br>  branch: main<br></code></pre></td></tr></table></figure></p></li><li><p>在shell中输入如下内容，通过浏览器访问浏览器访问(https://<你的Github用户名>.github.io/)查看是否部署成功<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g -d<br></code></pre></td></tr></table></figure></p></li></ul><h2 id="二添加删除或修改博客文章">二、添加删除或修改博客文章</h2><h3 id="添加博客文章">1. 添加博客文章</h3><ul><li><p>方法1:在shell中转到项目文件夹blog，并在shell中输入如下内容，添加名字为new_article的博客文章，在blog/source/_posts中找到new_article.md和new_article文件夹，对其修改即可添加博客文章<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo new post new_article<br></code></pre></td></tr></table></figure></p></li><li><p>方法2:在blog/source/_posts中创建一个文件夹，再在此文件夹里创建new_article.md和new_article文件夹，对其修改即可添加博客文章（也可以直接在blog/source/_posts里创建new_article.md和new_article文件夹）</p></li></ul><h3 id="删除或修改博客文章">2. 删除或修改博客文章</h3><p>在blog/source/_posts中找到xxx.md和xxx文件夹，对其删除或修改即可</p><h3 id="插入代码">3. 插入代码</h3><p>在md里输入如下代码即可</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">``` python<br>import numpy as np<br>a = 1<br>print(a)<br>```<br></code></pre></td></tr></table></figure><h3 id="插入图片">4. 插入图片</h3><ul><li><p>方法1: 在xxx文件夹中存放test.jpg，并在xxx.md中输入以下代码</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">&#123;% asset_img test.jpg example %&#125;<br></code></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">&lt;center&gt;<br>&lt;img src=&quot;test.jpg&quot; alt=&quot;图片描述&quot; width=&quot;50%&quot;/&gt;<br>&lt;/center&gt;<br></code></pre></td></tr></table></figure></li><li><p>方法2: 找到图片的网址为xxx，并在xxx.md中输入以下代码<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">&lt;center&gt;<br>&lt;img src=&quot;并在xxx.md中输入以下代码&quot; alt=&quot;图片名称&quot;   width=&quot;50%&quot;/&gt;<br>&lt;/center&gt;<br></code></pre></td></tr></table></figure></p></li></ul><h3id="在shell中输入如下内容通过浏览器访问httplocalhost4000-查看是否更改成功">5.在shell中输入如下内容，通过浏览器访问<ahref="http://localhost:4000">http://localhost:4000</a>查看是否更改成功</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure><h2 id="三参考内容">三、参考内容</h2><h3 id="httpsblog.csdn.netyaorongkearticledetails119089190">1. <ahref="https://blog.csdn.net/yaorongke/article/details/119089190">https://blog.csdn.net/yaorongke/article/details/119089190</a></h3><h3 id="httpszhcano.github.ioleancloudhexo开启评论和文章阅读量">2. <ahref="https://zhcano.github.io/LeanCloud+Hexo开启评论和文章阅读量/">https://zhcano.github.io/LeanCloud+Hexo开启评论和文章阅读量/</a></h3><h3 id="httpsfluid-dev.github.iohexo-fluid-docsguide">3. <ahref="https://fluid-dev.github.io/hexo-fluid-docs/guide/">https://fluid-dev.github.io/hexo-fluid-docs/guide/</a></h3>]]></content>
    
    
    <categories>
      
      <category>Instruction</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Github Pages Deployment</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>

<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>图神经网络总结</title>
    <link href="/2024/08/08/Different%20Paradigms%20of%20Graph%20Neuron%20Network/Different%20Paradigms%20of%20Graph%20Neuron%20Network/"/>
    <url>/2024/08/08/Different%20Paradigms%20of%20Graph%20Neuron%20Network/Different%20Paradigms%20of%20Graph%20Neuron%20Network/</url>
    
    <content type="html"><![CDATA[<h1 id="graph-neuron-networks-gnns">1. Graph Neuron Networks (GNNs)</h1><p><strong>思路：</strong> 巴拿赫不动点理论 (Banach's Fixed PointTheory) 为模型提供了理论依据。</p><p><strong>模型架构：</strong> 其输入为一张用向量标注的无向图<spanclass="math inline">\(G=(V,E)\)</span>（每个结点和边均被提前embedding为<spanclass="math inline">\(d\)</span>维），进行多轮更新得到中间输出<spanclass="math inline">\(H^{output}\)</span>，中间输出<spanclass="math inline">\(h^{output}_v\)</span>为表示图中结点的相关隐含信息向量，最终输出<spanclass="math inline">\(O\)</span>为图中结点类别信息。 （从<spanclass="math inline">\(h^{output}_v\)</span>到<spanclass="math inline">\(o^v\)</span>可以先将<spanclass="math inline">\(h^{output}_v\)</span>和<spanclass="math inline">\(x_v\)</span>拼接，然后加全连接层输出类别概率再使用softmax，最后进行argmax操作）</p><p>模型更新次数并不是固定的，在每一轮更新中，此模型对所有结点进行以下操作（将前馈神经网络的输出相加）：<span class="math display">\[h^{t+1}_{v} = f(x_v, x_co[v], h^t_ne[v],x_ne[v])=\sum_{u\in ne[v]}FNN([x_v, x_{(u,v)},h^t_u,x_u]) \]</span>其中，<span class="math inline">\(h^{t+1}_{v}\)</span>表示结点<spanclass="math inline">\(v\)</span>在<spanclass="math inline">\(t+1\)</span>时刻的隐状态，<spanclass="math inline">\(x_v, x_co[v]\)</span>分别表示结点<spanclass="math inline">\(v\)</span>和与结点<spanclass="math inline">\(v\)</span>相连的点的输入embedding，<spanclass="math inline">\(h^t_ne[v]\)</span>表示结点<spanclass="math inline">\(v\)</span>相连的点在<spanclass="math inline">\(t\)</span>时刻的隐状态，<spanclass="math inline">\(x_ne[v]\)</span>表示与结点<spanclass="math inline">\(v\)</span>相连的边的输入embedding。</p><p>当<spanclass="math inline">\(||H^{t+1}||_2-||H^{t}||_2&lt;\epsilon\)</span>时，终止更新得到输出<spanclass="math inline">\(h^{output}_v=h^v_{t+1}\)</span> <imgsrc="IMG_B14C45EDF889-1.jpeg" style="width:70.0%" alt="GNNs" /></p><p><strong>Loss function and optimaization：</strong> 基于Banach's FixedPointTheory，可以提出有约束优化，然后通过拉格朗日乘数法转化为无约束优化。<span class="math display">\[J=Loss + \lambda \cdot max(||\frac{\partialFNN}{\partial \mathbf{h}}||-c, 0), c\in (0,1)\]</span></p><p>在优化器方面，因为模型存在“参数共享”，即所有的<spanclass="math inline">\(FNN\)</span>参数是相通的，所以需要使用Almeida-Pineda算法更新参数信息。（参数共享的原因即为了方便处理多样化结构的图，只需要它们的embedding维度一致即可）</p><p><strong>Shortcomings：</strong> - 存在oversommothing问题 -没有完全将边和结点分开，在全连接层中边和结点的地位是等价的 -此模型如果用于处理有向图，无法考虑图的边是入边还是出边，此模型对于某一特定结点，其入边和出边地位是等同的。</p><h1 id="section"></h1><h1 id="convolutional-graph-neuron-networks-convgnns">2. ConvolutionalGraph Neuron Networks (ConvGNNs)</h1><p><strong>思路：</strong>ConvGNNs本质上受启发与CV领域的对图像进行卷积操作。但是在某一定义下，图像的邻居较为规则，结合邻居结点的信息进行卷积操作也非常简单可行，然而Graphs却结构较为多样，所以需要对其进行修改，让其可以充分使用邻居结点的信息。</p><p><strong>模型架构：</strong>输入一张无向图的结点embedding信息和adjacency matrix，即<spanclass="math inline">\((H^{(0)},A)\)</span>，中间输出图中所有结点的状态向量，最后输出结点的类别or图的类别信息，其中<spanclass="math inline">\(H^{(0)}\)</span>的第<spanclass="math inline">\(i\)</span>行为结点<spanclass="math inline">\(i\)</span>的<spanclass="math inline">\(d\)</span>维embedding向量。</p><p>模型层数固定，每一层参数互不共享，第<spanclass="math inline">\(i+1\)</span>层计算方法如下： <spanclass="math display">\[H^{(i+1)}=f_{i+1}(H^{(i)},A)=\sigma\left(\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}H^{(i)}W^{(i)}\right)\]</span>- <spanclass="math inline">\(\hat{A}=A+I\)</span>,使得更新时考虑到自己在上一时刻的信息- <span class="math inline">\(\hat{D}\)</span>中除对角线上元素为<spanclass="math inline">\(\hat{A}\)</span>对应行的<spanclass="math inline">\(L1\)</span>范数，其余元素均为0，<spanclass="math inline">\(\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}\)</span>用于对表示相邻关系的矩阵进行symmetricnormalization (对称归一化)，使得all colums and rows的<spanclass="math inline">\(L1\)</span>范数为1 - <spanclass="math inline">\(\sigma\)</span>为激活函数，按位激活 - <spanclass="math inline">\(T=\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}H^{(i)}\)</span>即求结点相邻结点向量的平均值，<spanclass="math inline">\(T\)</span>的第<spanclass="math inline">\(i\)</span>行表示结点<spanclass="math inline">\(i\)</span>的相邻结点的隐状态向量与其自身的隐状态向量的加权平均值（其中各结点的权重即<spanclass="math inline">\(\hat{D}^{-\frac12}\hat{A}\hat{D}^{-\frac12}\)</span>的第<spanclass="math inline">\(i\)</span>行） - <spanclass="math inline">\(TW^{(i)}\)</span>可看作“卷积”操作</p><figure><img src="o_image-10-gcn-framework.png" style="width:70.0%"alt="ConvGNNs" /><figcaption aria-hidden="true">ConvGNNs</figcaption></figure><p><strong>相关细节：</strong>在实际情况下，会使用类似于残差神经网络的结构，引入dropout，对Loss进行L2正则化处理,修改<span class="math inline">\(\hat{A}=A+\lambda I\)</span>等。</p><p><strong>Shortcomings：</strong> -此模型在每一层的计算中只考虑到了与其相邻的结点，没有考虑与其可达但不相邻的结点的信息，使其“感受野”受到一定的限制- 同GNN，如果用于处理有向图，无法充分使用有向图的入边出边信息。</p><h1 id="section-1"></h1><h1 id="recurrent-graph-neural-networks-recgnns">3. Recurrent GraphNeural Networks (RecGNNs)</h1><h2 id="gated-graph-neuron-networks-ggnns">(1) Gated Graph NeuronNetworks (GGNNs)</h2><p><strong>思路：</strong>GNN和ConvGNNs主要用于classification问题，在此基础上，GGNNs被提出，其对类似于LSTM的GRU模块进行改变并加入模型。（GRU可看作LSTM的一种优化，可以用于捕捉长距离的依赖关系，用于解决一些序列输出问题）</p><figure><img src="2381773f90e146868d4f6d0b4990813f.png" style="width:70.0%"alt="GRU模块" /><figcaption aria-hidden="true">GRU模块</figcaption></figure><p><strong>模型架构：</strong> 其输入为一张每一个结点均用<spanclass="math inline">\(d\)</span>维向量标注的有向图<spanclass="math inline">\(G=(V, E)\)</span>， 模型具有<spanclass="math inline">\(K\)</span>层，第一层即对所有结点如(1)初始化隐状态（<spanclass="math inline">\(v\)</span>表示结点编号），第二层以后每层类GRU模块数等于输入结点数，第<spanclass="math inline">\(t\)</span>层（<spanclass="math inline">\(t\)</span>大于1）的第<spanclass="math inline">\(v\)</span>个类GRU模块计算公式如(2)-(6)所示。</p><figure><img src="未命名-3.jpg" style="width:100.0%" alt="GGNNs计算公式" /><figcaption aria-hidden="true">GGNNs计算公式</figcaption></figure><p>其中<span class="math inline">\(A_v\)</span>是从<spanclass="math inline">\(A\)</span>中截取出来的两列组成的矩阵，截取outgoingedges的第<span class="math inline">\(v\)</span>列和incomingedges的第<span class="math inline">\(v\)</span>列。</p><p><img src="未命名-2.jpg" style="width:70.0%" alt="矩阵A的含义" />经过<span class="math inline">\(K\)</span>层得到<spanclass="math inline">\(H=[h^{(k)}_1; h^{(k)}_2;h^{(k)}_1;...h^{(k)}_{|{\mathcal{V}}|}]\)</span>，再经过一些输出层即可得到模型输出。</p><p><strong>特点：</strong> - 可以处理有向图 -使用GRU模块的变体，助于网络学习长期依赖关系 -类GRU模块参数也是共享的，本文使用Adam进行optimization</p><p><strong>另一个类似的模型：</strong>此模型可以用于处理与图有关的序列问题。 eg：输出两点间的最短路径序列但是感觉将如此复杂的模型用于如此简单的任务有小题大作之嫌 <imgsrc="../_resources/未命名-5.jpg" style="width:90.0%"alt="GATED GRAPH SEQUENCE NEURAL NETWORKS" /></p><h1 id="section-2"></h1><h1 id="graph-autoencoders-gaes">4. Graph Autoencoders (GAEs)</h1><h2 id="basic-gaes">(1) Basic GAEs<a href="#fn1" class="footnote-ref"id="fnref1" role="doc-noteref"><sup>1</sup></a></h2><p><strong>思路：</strong>本模型源将图卷积神经网络与自编码模型相结合构造出可以用于图结点关系预测的模型。<img src="未命名2.jpg" style="width:70.0%"alt="Traditional Autoencoder Model" />传统的自编码模型如上图所示，输入<spanclass="math inline">\(X\)</span>，输出<spanclass="math inline">\(\hat{X}\)</span>，即对X的估计。此模型可以用于词嵌入，图像特征提取，图像降噪增强等方面。</p><p><strong>模型架构：</strong>此模型输入一张不完整的，可以添加link（无向边）的无向图<spanclass="math inline">\(G=(V, E)\)</span>，先得到图<spanclass="math inline">\(G\)</span>的结点embedding的<spanclass="math inline">\(N\times D\)</span>维矩阵<spanclass="math inline">\(X\)</span>与<span class="math inline">\(N\timesN\)</span>维邻接矩阵<span class="math inline">\(A\)</span>。</p><figure><img src="未命名-4.jpg" style="width:70.0%" alt="Basic GAEs" /><figcaption aria-hidden="true">Basic GAEs</figcaption></figure><p>然后进入encoder层（Paper中称为inferencemodel）进行两层ConvGNN后并采样得到中间的latent variable，即<spanclass="math inline">\(N\times D\)</span>维矩阵<spanclass="math inline">\(Z\)</span>，encoder层具体计算方法如下所示。</p><p><spanclass="math display">\[\widetilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\]</span>- ecoder第一层： <span class="math display">\[\bar{X}  =ConvGNN(X,A)=ReLU(\widetilde{A}XW_0)\]</span> - encoder第二层： <spanclass="math display">\[\mu =ConvGNN_\mu(\bar{X},A)=\widetilde{A}\bar{X}W_1\]</span> <spanclass="math display">\[log\sigma =ConvGNN_\sigma(\bar{X},A)=\widetilde{A}\bar{X}W_2\]</span> -encoder计算Z的分布并采样： <spanclass="math display">\[Z_{var}=\mu+\sigma * \epsilon\]</span> <spanclass="math display">\[\epsilon\sim N(0,1)\]</span> 即<spanclass="math inline">\(Z_{var}  \sim N(\mu, \sigma^2)\)</span>然后对随机变量矩阵<spanclass="math inline">\(Z_{var}\)</span>采样得到<spanclass="math inline">\(Z\)</span></p><p>最后通过decoder层（Paper中称为generative model）得到<spanclass="math inline">\(\hat{A}\)</span>，即补充完图中缺失的link后的邻接矩阵，，decoder层具体计算方法如下所示。<span class="math display">\[P(A_{ij}=1|\bold{z_i}, \bold{z_j}) =\sigma(\bold{z^T_i z_j})\]</span> 然后再通过特定的阈值推断<spanclass="math inline">\(A_{ij}\)</span>的值。</p><p><strong>相关细节：</strong> -本文中应用KL散度于损失函数中，但目前对损失函数的理论依据不太了解 -本文中化器用Adam ## (2) GAEs for network embedding ## (3) GAEs for graphgeneration</p><h1 id="section-3"></h1><h1 id="spatial-temporal-graph-neural-networks-stgnns">5.Spatial-Temporal Graph Neural Networks (STGNNs)</h1><section id="footnotes" class="footnotes footnotes-end-of-document"role="doc-endnotes"><hr /><ol><liid="fn1"><p>https://towardsdatascience.com/tutorial-on-variational-graph-auto-encoders-da9333281129<ahref="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>图神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Event-Event Relation Extraction</title>
    <link href="/2024/08/08/Event-Event%20Relation%20Extraction/Event-Event%20Relation%20Extraction/"/>
    <url>/2024/08/08/Event-Event%20Relation%20Extraction/Event-Event%20Relation%20Extraction/</url>
    
    <content type="html"><![CDATA[<h1 id="event-event-relation-extraction">Event-Event RelationExtraction</h1><h3 id="related-definitions">1. Related Definitions</h3><ol type="1"><li><p><strong>事件：</strong> An event is an occurrence of societalimportance, typically happening at a specific time and location,involving a set of participants. It can be represented as <spanclass="math inline">\((action\; or \;status, persons, time,location)\)</span>, action or status can be also called as a<strong>trigger word</strong>. Besides, in a graph, a node with a tagwritten its trigger word and with other subsidiary information nodesconnected can represent a event briefly. <imgsrc="Event%20in%20Graph.jpg#w70" alt="Event in Graph" /></p></li><li><p><strong>事件关系抽取：</strong>即抽取事件之间的关系，事件之间的关系包括但不限于因果关系(CasualRelation)，子事件关系(Subevent Relation)，时序关系(TemporalRelation)，等同关系等，这些关系大类里又可以细分为诸多子关系。比如，时序关系可以分为before，after和overlapping等子关系。</p></li><li><p><strong>事件因果关系抽取：</strong>即抽取事件之间的因果关系(Casual Relation)，因果关系也可以细分为explicitcasualty和implicit casualty等子关系。</p></li></ol><h3 id="事件抽取与事件关系抽取的相关工作">2.事件抽取与事件关系抽取的相关工作</h3><ul><li><p><strong>GraphERE</strong> <img src="GraphERE.jpg"style="width:80.0%" alt="GraphERE" />此模型可以用于抽取文本中的一系列events及其关系，首先，包含多个events的文本被输入，然后相应的解析器解析成两种不同的Graphs(AMR andIE)，再对每一个事件进行增强嵌入得到event向量，最后通过transformer和DeepGraph Learning获得关系抽取结果图。</p></li><li><p><strong>GraphIE</strong>可以给定一句包含事件的语句作为模型输入，模型通过decoder输出各个token的tag，即：某词是事件的触发词，某词是事件的论元…然后就可以使用这些知识构建图。 <img src="GraphIE.jpg"style="width:80.0%" alt="GraphIE" /></p></li><li><p><strong>ERNIE</strong>ERNIE是一种新的预训练模型，可看作Transformer的decoder架构的一种变体，可以结合大规模文本语料库和知识图谱(KGs)，利用知识图谱中丰富的结构化知识事实来增强预训练模型的语言理解能力。<img src="未命名.jpg" style="width:80.0%" alt="ERNIE" />如图所示，此模型用于输入一段文本与文本中输入文本中某一些tokens对应的entities，输出一段文本与entity对应的输入tokens的位置，输出的文本可以是对输入mask的推测，对输入的下一句话的预测等。实验也证明它比BERT等baseline模型效果要好。</p></li><li><p><strong>Prompt-based event relation identification withConstrained Prefix Attention mechanism</strong>本文提出了一种新的事件关系抽取框架，输入两个分别包含1个event的语句，系统即可判断出两个event之间的并且属于<spanclass="math inline">\(relation\;set=[casual, \;temporal,\;unrelated]\)</span> 的关系。 <img src="11.jpg"alt="Prompt Based Model" />在创新点方面，本文主要提出了两点改进：</p></li></ul><ol type="1"><li>在输入中添加包含一系列关系名称的 <spanclass="math inline">\(prefix=relation\;set\)</span>，并在BART模型中添加prefix-biased fully-connectedattention层，让关系对应的attentionbias可以体现在每一个输入的token中。</li><li>Inspired by ZLPR，作者提出了一种特别的损失函数，可以考虑中间过程并且更加关注正确的prefix。除此以外，交叉熵损失函数也被作为最终损失函数的一部分。</li></ol><ul><li><strong>MetaIE</strong></li></ul><ol type="1"><li>此模型可以输入一段文本，输出序列标注和spans。</li><li>此模型思路相对较为简单，即通过Symbolic KnowledgeDistillation将参数量大的Teacher Model变为Student Model。</li><li>此模型使用的Teacher Model是GPT-3.5-turbo via LLM Prompting within-context learning，Student Model是RoBERTa-Large。</li><li>在构建训练集时，本文使用大语言模型对海量的数据进行提问整合，减小了构建数据集的难度。</li><li>虽然此方法能够通过大模型训练出效果较好的小模型，但是，此方法也会将大模型的bias带入小模型。</li></ol><p><img src="MetaIE.jpg" alt="MetaIE" /> - <strong>Selecting OptimalContext Sentences for Event-Event Relation Extraction</strong>此模型可以输入一段document并标注出event的触发词语，输出event之间的关系。在创新方面，此模型主要抓住大语言模型无法理解长文本这一问题作出改进，提取出输入的文本中不包含triggerword的但是与事件关系有关的语句作为关键语句，将关键语句和包含triggerword的语句整合送入大语言模型得到抽取结果。</p><ul><li><strong>Mastering Context-to-Label Representation Transformation forEvent Causality Identification with Diffusion Models</strong>此模型可以输入两句描述event的语句，输出它们之间的关系。此模型受启发于CV领域的diffusionmodel(先添加高斯噪声，后逆向还原图像)，训练出一个可以将文本中的“噪声”（不相关文本）剔除的模型。<img src="Diffusion%20Model.jpg" alt="Diffusion Model" /></li></ul><h3 id="summary">3. Summary</h3><ol type="1"><li><strong>任务形式差别</strong>在任务形式方面，有些是给定了带有event的语句要求抽取出其关系；有些是给定一段文本，要求先抽取出event后找出其关系。</li><li><strong>方法差别</strong>在实现方法方面，一般是将对话大语言模型，预训练模型(PLM)，知识图谱，提示工程中的几个内容相结合成新的模型实现。</li></ol><h3 id="current-challenges">4. Current Challenges</h3><ol type="1"><li>因果关系中的explicit casualty相对较容易提取，但是implicitcasualty因为没有明确的关键词提示较难提取。</li><li>目前模型需要大规模的训练集进行训练，然而目前训练集规模普遍偏小。eg:the largest existing dataset Event Story Line only contains 258documents, and the training data in practical application scenarios isscarcer than Event Story Line.</li><li>目前以大语言模（如GhatGPT）为基础的事件及其关系抽取模型存在bias与hallucination（大模型幻觉），并且在模型中添加InContext Learning或者Chain ofThoughts后会加剧hallucination这一现象。除此以外，大模型对提问的prompt非常敏感，很难调整到合适的prompt并且缺乏理论依据。</li><li>可能输入语句中存在大量不相关的内容导致大量noise产生，从而影响模型效果。</li><li>有一些事件使用过长的语句描述并且其关系也要结合长上下文进行理解，然而目前大语言模型对长上下文的理解能力有限，比如BERT模型的输入最长只有512个token。</li><li>有一些文本中两个事件的触发词语之间的distance较长，即两个触发词之间相隔的token数较多，模型难以抽取之间的关系。</li><li>对于一些zero-shot的问题无法得到较好的抽取结果</li></ol>]]></content>
    
    
    <categories>
      
      <category>事件关系抽取</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Advanced Paradigm of GNN</title>
    <link href="/2024/08/08/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/"/>
    <url>/2024/08/08/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/Advanced%20Paradigm%20of%20Graph%20Neuron%20Network/</url>
    
    <content type="html"><![CDATA[<h1 id="section"></h1><ul><li><p><strong>Meta-Path</strong>元路径（Meta-Path）是图数据挖掘和分析中的一个重要概念，尤其是在异构信息网络（HeterogeneousInformation Network,HIN）中应用广泛。元路径可以理解为在异构信息网络中连接不同类型节点的一条路径，这条路径按照特定的节点类型和边类型顺序排列。</p></li><li><p><strong>Heterogeneous Graph</strong>异质图指具有不同类型的结点或者边的图，若其具有不同类型的边，其可看作多片同质图的叠加。# ## 1. GTN (Graph Transformer Network) <img src="GTNs.jpg"alt="GTNs.jpg" /></p></li></ul><p>整个模型架构可以看成是：在由GraphTransformer层学习到的多片元路径图（meta-pathgraphs）上进行GCN。可以用于异质图分类，异质图结点分类，异质图边链接预测等任务。</p><p><strong>Advantages</strong> 1.传统的GNN将所有的边都视作同一种类型，而GT层的引入可以使得模型能够较好地学习不同类型的异质边的特点并将其转化为元路径（同质边）供GNN进行操作。2. 因为模型会对输入的权重和矩阵添加identifymatrix，所以模型可以学习到变长的元路径权重和矩阵（最大长度为GT层的层数+1，最小长度为0），以更好地用于下游任务。消融性实验也证明学习变长路径的重要性。3.除此以外，实验也证明GT学习出的元路径（无需预定义元路径）可以非常好地对学习nodesrepresentation.</p><p><strong>Shortcomings</strong> 1.本方法虽然名为GT，但是GT中的每一层没有体现出transformer中的self-attention机制（使用Query，Key和Vector），只有简单的attention机制。可以结合自注意力，通过图的结构得到卷积核。2. 本方法GT层只有卷积，可以加入池化层 (Graph Level Pooling)对重要特征进行提取。 # - <strong>Weisfeiler-Lehamn Test</strong>用于判断两个图是否可能同构，当某一次迭代更新标签后两个图相同的标签出现的次数不一致，则两个图不可能同构（不同构）。<img src="20191219161502970.png" alt="20191219161502970.png" /> <imgsrc="WLtest流程1-4.png" alt="WLtest流程1-4.png" /></p><h1 id="section-1"></h1><h2 id="gin-graph-isomorphism-network">2. GIN (Graph IsomorphismNetwork)</h2><p>在本文中，作者提出GCN可以看作WL-test的一种变形，当GCN的聚合函数满足一定条件，其表征能力与WL-test相同。（但是现有GCN达不到）在此基础上，作者提出GIN，即一种可以逼近WL-test的GNN。</p>]]></content>
    
    
    <categories>
      
      <category>图神经网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Event-Event Relation Extraction Datasets</title>
    <link href="/2024/07/31/event-to-event-relation-extraction-dataset/"/>
    <url>/2024/07/31/event-to-event-relation-extraction-dataset/</url>
    
    <content type="html"><![CDATA[<h1 id="event-event-relation-extraction-datasets">Event-Event RelationExtraction Datasets</h1><h2 id="maven-ere">1. <ahref="https://github.com/THU-KEG/MAVEN-ERE">MAVEN-ERE</a> 🤩🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://arxiv.org/pdf/2211.07342">https://arxiv.org/pdf/2211.07342</a></p><p><strong>Data Distribution:</strong> - 4,480 documents - 168fine-grained event types - 112,276 mentions - 103,193 event coreferencechains - 1,216,217 temporal relations (BEFORE, OVERLAP, CONTAINS,SIMULTANEOUS, BEGINS-ON, ENDS-ON) - 15,841 subevent relations - 57,992causal relations (CAUSE, PRECONDITION)</p><p><strong>Data Format:</strong> <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;f28bce270df5a122c09365002d247e76&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for each document</span><br>  <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;United States occupation of Nicaragua&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the tiltle of the document</span><br>  <span class="hljs-attr">&quot;tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for tokenized document content. each item is a tokenized sentence</span><br>    <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;The&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;United&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;States&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;occupation&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;of&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Nicaragua&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;from&quot;</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-string">&quot;1912&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;to&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;1933&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;was&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;part&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;of&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;the&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Banana&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Wars&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;,&quot;</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-string">&quot;when&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;the&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;US&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;military&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;intervened&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;in&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;various&quot;</span><span class="hljs-punctuation">,</span> <br>    <span class="hljs-string">&quot;Latin&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;American&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;countries&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;from&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;1898&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;to&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;1934&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;.&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;sentences&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// untokenized sentences of the document. each item is a sentence (string)</span><br>      <span class="hljs-string">&quot;The United States occupation of Nicaragua from 1912 to 1933 was part of the Banana Wars, when the US military intervened in various Latin American countries from 1898 to 1934.&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;events&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for annotated events, each item is a dict for an event (coreference chain)</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;EVENT_0341c5cced5545ffe7c543b7a155bfa8&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for the event (coreference chain)</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Choosing&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the event type</span><br>            <span class="hljs-attr">&quot;type_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">25</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the numerical id for the event type, consistent with MAVEN</span><br>            <span class="hljs-attr">&quot;mention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for the coreferential event mentions of the chain, each item is a dict. they have coreference relations to each other</span><br>                <span class="hljs-punctuation">&#123;</span><br>                    <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;a75ba55cadad23555a0ffc9454088687&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for the event mention</span><br>                    <span class="hljs-attr">&quot;trigger_word&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;assumed&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// a string of the trigger word or phrase</span><br>                    <span class="hljs-attr">&quot;sent_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">3</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the index of the corresponding sentence, starts with 0</span><br>                    <span class="hljs-attr">&quot;offset&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// the offset of the trigger words in the tokens list</span><br>                <span class="hljs-punctuation">&#125;</span><br>            <span class="hljs-punctuation">]</span><br>        <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;TIMEX&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for annotated temporal expressions (TIMEX), each item is a dict for a TIMEX</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;TIME_833e41f3304210094101eca59905055e&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// an unique string for the TIMEX</span><br>      <span class="hljs-attr">&quot;mention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1912&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// a string of the mention of the TIMEX</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;DATE&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the type of the TIMEX</span><br>      <span class="hljs-attr">&quot;sent_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-comment">// the index of the corresponding sentence, starts with 0</span><br>      <span class="hljs-attr">&quot;offset&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">7</span><span class="hljs-punctuation">,</span> <span class="hljs-number">8</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// the offset of the trigger words in the tokens list</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;temporal_relations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-comment">// a list for annotated temporal relations between events (and TIMEXs)</span><br>    <span class="hljs-attr">&quot;BEFORE&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for temporal relations of BEFORE type</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;TIME_id_2&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// a temporal relation instance, means EVENT_id_1 BEFORE TIME_id_2</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;OVERLAP&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// all the following types are similar</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;CONTAINS&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;SIMULTANEOUS&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;ENDS-ON&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;BEGINS-ON&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;causal_relations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-comment">// a list for annotated causal relations between events</span><br>    <span class="hljs-attr">&quot;CAUSE&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>  <span class="hljs-comment">// a list for causal relations of CAUSE type</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// a causal relation instance, means EVENT_id_1 CAUSE EVENT_id_2</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;PRECONDITION&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// the PRECONDITION type is similar</span><br>      <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;subevent_relations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-comment">// a list for annotated subevent relations between events</span><br>    <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;EVENT_id_1&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;EVENT_id_2&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-comment">// a subevent relation instance, means EVENT_id_2 is a subevent of EVENT_id_1</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></p><h2 id="choice-of-plausible-alternatives-copa">2.<ahref="https://asgordon.github.io/copa.html">Choice of PlausibleAlternatives (COPA)</a></h2><p><strong>Paper:</strong> <ahref="https://asgordon.github.io/publications/AAAI-SPRING11A.PDF">https://asgordon.github.io/publications/AAAI-SPRING11A.PDF</a></p><p><strong>Data Distribution:</strong> - 1000 groups - each group has 2relations, one is correct and the other is false. - only 2 types ofrelation (cause, effect)</p><p><strong>Data Format:</strong> <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">item</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;3&quot;</span> <span class="hljs-attr">asks-for</span>=<span class="hljs-string">&quot;cause&quot;</span> <span class="hljs-attr">most-plausible-alternative</span>=<span class="hljs-string">&quot;2&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>The women met for coffee.<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">a1</span>&gt;</span>The cafe reopened in a new location.<span class="hljs-tag">&lt;/<span class="hljs-name">a1</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">a2</span>&gt;</span>They wanted to catch up with each other.<span class="hljs-tag">&lt;/<span class="hljs-name">a2</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">item</span>&gt;</span><br></code></pre></td></tr></table></figure></p><h2 id="e-care">3. <ahref="https://github.com/Waste-Wood/e-CARE?tab=readme-ov-file">e-CARE</a></h2><p><strong>Paper:</strong> <ahref="https://arxiv.org/pdf/2205.05849">https://arxiv.org/pdf/2205.05849</a></p><p><strong>Data Distribution:</strong> - 21,324 groups (7,617 groups ofcause relation and 7,311 groups of effect relation) - each group has 2relations (one is correct and the other is false) and a explanation.</p><p><strong>Data Format:</strong> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs jsonl">&#123;&quot;index&quot;: &quot;train-0&quot;, <br>&quot;premise&quot;: &quot;There is a light rain today.&quot;, <br>&quot;ask-for&quot;: &quot;effect&quot;, <br>&quot;hypothesis1&quot;: &quot;The roots of many plants are not moistened by rain.&quot;, <br>&quot;hypothesis2&quot;: &quot;Tourists have seen many ripples.&quot;, <br>&quot;label&quot;: 0&#125;<br><br>&#123;&quot;index&quot;: &quot;train-0&quot;, <br>&quot;cause&quot;: &quot;There is a light rain today.&quot;, <br>&quot;effect&quot;: &quot;The roots of many plants are not moistened by rain.&quot;, <br>&quot;conceptual_explanation&quot;: &quot;Precipitation reaches soil surfaces.&quot;&#125;<br></code></pre></td></tr></table></figure></p><h2 id="esl">4. <ahref="https://github.com/tommasoc80/EventStoryLine?tab=readme-ov-file">ESL</a>🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/W17-2711.pdf">https://aclanthology.org/W17-2711.pdf</a></p><p><strong>Data Distribution:</strong> - 258 documents with 22 topics -7,275 event mentions - three types of relations (Temporal, Co-Reference,Plot) - Temporal relation can be divided into contains, before, afterand overlap.</p><h2 id="ctb">5. <ahref="https://github.com/paramitamirza/Causal-TimeBank">CTB</a>🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/W14-0702.pdf">https://aclanthology.org/W14-0702.pdf</a></p><p><strong>Data Distribution:</strong> - 6,811 EVENTs (only instantiatedevents by MAKEINSTANCE tag of TimeML) - 5,118 TLINKs (temporal links) -171 CSIGNALs (causal signals) - 318 CLINKs (causal links)</p><h2 id="meci">6. <ahref="https://github.com/nlp-uoregon/meci-dataset">MECI</a> 🤩🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/2022.coling-1.206.pdf">https://aclanthology.org/2022.coling-1.206.pdf</a></p><p><strong>Data Distribution:</strong> - 5 languages, 5 topics, morethan 1,000 articles per topic for each language - the annotation methodis same as ESL</p><p><strong>Data Format:</strong> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs tsvx">TextThe policy document sets out what must be done to deliver a global response &quot; that leaves no - one behind &quot; , reduces global vulnerability to future pandemics , builds resilience to future shocks , especially climate change , and addresses &quot; the severe and systemic inequalities exposed by the pandemic &quot; .The document focuses on three main operational approaches , namely delivering a large coordinated and comprehensive response on health ; adopting policies to address the adverse human rights , humanitarian , and socioeconomic , humanitarian effects ; and creating a recovery process that &quot; builds back better &quot; .As part of the United Nations &#x27; response , the UN Secretary - General has been prominent in ensuring the maintenance of normal UN operations , in launching events , and making in appeals on behalf of the United Nations System , including for the world &#x27;s first global ceasefire and for billions of dollars in funding .He has also defended the WHO &#x27;s response to the crisis and fought back against COVID - 19 misinformation .As the UN &#x27;s response became more systematized , he been issuing policy briefs , by theme , population , and region , to aid governments in how to address the consequences of the pandemic .<br><br>EventT0doneEVENT42<br>EventT1deliverEVENT50<br>EventT10pandemicEVENT294<br>EventT11focusesEVENT320<br><br>RelationT4T29CauseEffecttruereducessets out<br>RelationT29T4EffectCausetruesets outreduces<br>RelationT9T21NoReltrueexposedfought<br>RelationT9T3NoReltrueexposedleaves<br></code></pre></td></tr></table></figure></p><h2 id="hieve">7. <ahref="http://takelab.fer.hr/hievents.rar">HiEve</a></h2><h5 id="没有找到数据集">没有找到数据集</h5><p><strong>Paper:</strong> <ahref="http://www.lrec-conf.org/proceedings/lrec2014/pdf/1023_Paper.pdf">http://www.lrec-conf.org/proceedings/lrec2014/pdf/1023_Paper.pdf</a></p><h2 id="matres">8. MATRES</h2><p><strong>Paper:</strong> <ahref="https://arxiv.org/pdf/1804.07828">https://arxiv.org/pdf/1804.07828</a></p><p><strong>Data Format:</strong> <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs txt">WSJ_20130322_159apologizedhappened15VAGUE<br>WSJ_20130322_159apologizedwrapped16BEFORE<br>WSJ_20130322_159apologizedseemed110BEFORE<br></code></pre></td></tr></table></figure></p><h2 id="tddiscourse">9. <ahref="https://github.com/aakanksha19/TDDiscourse">TDDiscourse</a>🤩🤩</h2><p><strong>Paper:</strong> <ahref="https://aclanthology.org/W19-5929.pdf">https://aclanthology.org/W19-5929.pdf</a></p><p><strong>Data Distribution:</strong> - Expand from TimeBank (containsmore temopral links), contains 6,150 relation pairs in TDD-Man and about38,000 relation pairs in TDD-Auto - it contains more long distiancerelation mentions (很多数据集只标注近距离的trigger words之间的关系) -relations include after, before, simultaneous, include andis-included</p><p><strong>Data Format:</strong> <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs txt">APW19980227.0468e1e8ii<br>APW19980227.0468e1e9ii<br>APW19980227.0468e1e10a<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>datasets</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>归一化(Normalization)的一些方法</title>
    <link href="/2024/07/24/%E5%85%B3%E4%BA%8E%E5%BD%92%E4%B8%80%E5%8C%96%20(Normalization)/"/>
    <url>/2024/07/24/%E5%85%B3%E4%BA%8E%E5%BD%92%E4%B8%80%E5%8C%96%20(Normalization)/</url>
    
    <content type="html"><![CDATA[<h1 id="行归一化">行归一化</h1><h2 id="矩阵行l1范数-or-矩阵行l2范数为1">(矩阵行L1范数 or矩阵行L2范数为1)</h2><ol type="1"><li><p><strong>计算行范数</strong>：首先计算原矩阵每一行的<spanclass="math inline">\(L_2\)</span>范数。</p></li><li><p><strong>创建范数矩阵</strong>：将这些范值构成一个对角矩阵<spanclass="math inline">\(D\)</span>，其中对角线上的元素是原矩阵的行范数，非对角线上的元素是0。</p></li><li><p><strong>逆范数矩阵</strong>：计算对角矩阵<spanclass="math inline">\(D\)</span>的逆矩阵<spanclass="math inline">\(D^{-1}\)</span>，其对角线上的元素是对应行范数的倒数。</p></li><li><p><strong>矩阵相乘</strong>：将原矩阵<spanclass="math inline">\(M\)</span>与逆范数矩阵<spanclass="math inline">\(D^{-1}\)</span>相乘，得到归一化后的矩阵<spanclass="math inline">\(M_{\text{norm}}\)</span>。</p></li></ol><p>数学上，如果<span class="math inline">\(M\)</span>是原始矩阵，<spanclass="math inline">\(D\)</span>是行范数构成的对角矩阵，那么归一化后的矩阵<spanclass="math inline">\(M_{\text{norm}}\)</span>可以通过以下公式计算：<span class="math display">\[M_{\text{norm}} = M \cdotD^{-1}\]</span></p><h1 id="对称归一化">对称归一化</h1><h2id="矩阵行与列l1范数均为1-or-矩阵行与列l2范数均为1">(矩阵行与列L1范数均为1or 矩阵行与列L2范数均为1)</h2><p><span class="math inline">\(D^{-1/2} AD^{-1/2}\)</span>这种归一化方法通常被称为对称归一化（symmetricnormalization）或双归一化（doublenormalization），它在数学和机器学习领域中有着特定的应用和效果。下面是这种归一化方法的详细说明和效果：</p><h3 id="归一化过程">归一化过程：</h3><ol type="1"><li><p><strong>构建对角矩阵<spanclass="math inline">\(D\)</span></strong>：首先，计算矩阵<spanclass="math inline">\(A\)</span>的行<spanclass="math inline">\(L_2\)</span>范数，用这些范数构建对角矩阵$D)。</p></li><li><p><strong>计算<spanclass="math inline">\(D^{-1/2}\)</span></strong>：接着，计算<spanclass="math inline">\(D\)</span>的逆矩阵的平方根，即<spanclass="math inline">\(D^{-1/2}\)</span>。这个操作将每个行范数取倒数再开平方。</p></li><li><p><strong>归一化操作</strong>：通过矩阵乘法<spanclass="math inline">\(D^{-1/2} A D^{-1/2}\)</span>对<spanclass="math inline">\(A\)</span>进行操作。</p></li></ol><h3 id="达到的效果">达到的效果：</h3><ol type="1"><li><p><strong>行和列的<spanclass="math inline">\(L_2\)</span>范数归一化</strong>：归一化后的矩阵<spanclass="math inline">\(A\)</span>中，每一行和每一列的<spanclass="math inline">\(L_2\)</span>范数都被缩放至1。这意味着矩阵<spanclass="math inline">\(A\)</span>中的每个向量（行和列）都变成了单位向量。</p></li><li><p><strong>数值稳定性</strong>：这种归一化可以提高数值计算的稳定性，因为它减少了由于某些行或列具有较大数值而导致的数值问题。</p></li><li><p><strong>特征值和奇异值的缩放</strong>：归一化后的矩阵<spanclass="math inline">\(A\)</span>的特征值和奇异值通常会被缩放至更小的范围，这有助于某些算法的性能和数值稳定性。</p></li><li><p><strong>数据预处理</strong>：在机器学习和数据分析中，这种归一化可以作为数据预处理的步骤，确保不同的特征具有相同的尺度，有助于算法的收敛和性能。</p></li><li><p><strong>对称性保持</strong>：如果矩阵<spanclass="math inline">\(A\)</span>是对称的，这种归一化方法保持了矩阵的对称性。</p></li><li><p><strong>改善条件数</strong>：通过缩放行和列，可以改善矩阵<spanclass="math inline">\(A\)</span>的条件数，即最大奇异值与最小奇异值的比率。一个较小的条件数意味着矩阵更接近于正交矩阵，数值解法更稳定。</p></li><li><p><strong>在谱聚类中的应用</strong>：在谱聚类算法中，这种归一化方法常用于预处理相似性矩阵或拉普拉斯矩阵，以提高算法的效率和效果。</p></li></ol><h3 id="数学解释">数学解释：</h3><p>归一化操作<span class="math inline">\(D^{-1/2} AD^{-1/2}\)</span>等价于先将<spanclass="math inline">\(A\)</span>的每一行通过<spanclass="math inline">\(D^{-1/2}\)</span>进行缩放，使得它们成为单位向量，然后对每一列也进行相同的操作。数学上，这可以表示为：</p><p><span class="math display">\[D^{-1/2} A D^{-1/2} = \left( D^{-1/2}A^T D^{-1/2} \right)^T\]</span></p><p>这意味着操作是对称的，即先对行操作再对列操作，或者先对列操作再对行操作，结果是相同的。</p><p>这种归一化方法在理论和实际应用中都很有用，特别是在需要处理矩阵特性（如特征值、奇异值、条件数）的算法中。</p>]]></content>
    
    
    <categories>
      
      <category>Basics Theory</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据归一化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Instruction of Deploy a Blog through Github Pages and Hexo</title>
    <link href="/2024/06/12/Instruction/Instruction/"/>
    <url>/2024/06/12/Instruction/Instruction/</url>
    
    <content type="html"><![CDATA[<h1id="instruction-of-deploy-a-blog-through-github-pages-and-hexo">Instructionof Deploy a Blog through Github Pages and Hexo</h1><p>This is an instruction of deploy a blog through Github Pages andHexo. Check <a href="https://hexo.io/docs/">documentation</a> for moreinfo.</p><h2 id="一初始化github-pages">一、初始化Github Pages</h2><h3 id="一目标">（一）目标</h3><p>部署带有一篇博客的个人博客网站，并且可以统计每一篇博客和整个网站的浏览量和浏览人数。</p><h3 id="二实现方法">（二）实现方法</h3><h3 id="注册个人github账号在自己电脑上安装git和nodejs">1. 注册个人<ahref="https://github.com/">Github账号</a>，在自己电脑上安装<ahref="https://git-scm.com/downloads">Git</a>和<ahref="https://nodejs.org/en">NodeJS</a></h3><p>NodeJS直接点击链接在网页里面找到LTS版本的符合自己电脑的安装包下载安装即可</p><h3 id="在github中创建一个公有仓库仓库名为.github.io">2.在Github中创建一个公有仓库，仓库名为<用户名>.github.io</h3><h3 id="安装hexo并初始化">3. 安装Hexo并初始化</h3><ul><li><p>在bash shell或者zsh shell中输入如下内容完成Hexo安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo npm install -g hexo-cli<br></code></pre></td></tr></table></figure></p></li><li><p>待显示安装完成后，输入如下内容查看版本，检查是否正确安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo npm install -g hexo-cli<br></code></pre></td></tr></table></figure></p></li><li><p>在shell中转到用于存储Hexo项目的文件夹，输入如下内容创建一个新Hexo项目<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo init blog<br><span class="hljs-built_in">cd</span> blog<br>npm install<br></code></pre></td></tr></table></figure></p></li><li><p>在shell中输入如下内容，在本地生成相关静态文件(hexo g)并启动(hexos)，通过浏览器访问浏览器访问 <ahref="http://localhost:4000">http://localhost:4000</a> 查看效果<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure></p></li><li><p>如果看到如下图片则说明部署成功</p><center><p><img src="hexo_init.jpg" alt="初始化后界面示意图" width="80%"/></p></center></li></ul><h3 id="更换fluid主题并配置相关字段使界面更加美观实用">4.更换Fluid主题，并配置相关字段，使界面更加美观实用</h3><ul><li><p>通过此网址<ahref="https://github.com/fluid-dev/hexo-theme-fluid">https://github.com/fluid-dev/hexo-theme-fluid</a>下载Fluid主题并将文件夹重命名为fluid，存放于blog/themes文件夹中</p></li><li><p>打开blog/_config.yml配置文件，修改theme，language和title等字段<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">theme:</span> fluid <span class="hljs-meta"># 一定要改</span><br><span class="hljs-symbol">post_asset_folder:</span> true <span class="hljs-meta"># 一定要改，方面后期发布修改博客文章  </span><br><span class="hljs-symbol">language:</span> <span class="hljs-built_in">zh</span>-CN <span class="hljs-meta"># 酌情选择（决定导航栏的显示语言）</span><br><span class="hljs-symbol">title:</span> a blog <span class="hljs-meta"># 酌情设置（决定浏览器tab的显示内容）</span><br></code></pre></td></tr></table></figure></p></li><li><p>与上操作类似，打开blog/thems/fluid/_config.yml配置文件，修改blog_title，text等字段</p></li><li><p>在shell中输入如下代码，在Blog中添加About页面<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haxe">hexo <span class="hljs-keyword">new</span> <span class="hljs-type">page</span> about<br></code></pre></td></tr></table></figure></p></li><li><p>之后可以在blog/source/about/index.md中修改文件调整页面内容</p></li><li><p>再次在shell中输入如下内容，通过浏览器访问浏览器访问 <ahref="http://localhost:4000">http://localhost:4000</a>查看更换主题后的效果 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure></p></li></ul><h3 id="设置阅读量统计">5. 设置阅读量统计</h3><ul><li><p>进入<ahref="https://console.leancloud.cn/">LeanCloud官网</a>注册账号，实名认证并验证邮箱</p></li><li><p>如下图所示创建应用</p><center><p><img src="leancloud-1.jpg" alt="创建应用" width="80%"/></p></center></li><li><p>如下图所示，进入设置-应用凭证，记录AppID，AppKey和REST API服多器地址</p><center><p><img src="leancloud-2.jpg" alt="id and key" width="80%"/></p></center></li><li><p>如下图所示，创建类用于存储访问数据，类名必须严格按照图片中的类名设置</p><center><p><img src="leancloud-3.jpg" alt="id and key" width="80%"/></p></center></li><li><p>打开blog/thems/fluid/_config.yml配置文件,修改如下内容<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># 一定要改</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">web_analytics:</span><br><span class="hljs-symbol">  enable:</span> true <br><span class="hljs-symbol"></span><br><span class="hljs-symbol">leancloud:</span><br><span class="hljs-symbol">    app_id:</span> <span class="hljs-params">&lt;AppID&gt;</span><br><span class="hljs-symbol">    app_key:</span> <span class="hljs-params">&lt;AppKey&gt;</span><br><span class="hljs-symbol">    server_url:</span> <span class="hljs-params">&lt;REST API 服多器地址&gt;</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">views:</span><br><span class="hljs-symbol">      enable:</span> true<br><span class="hljs-symbol">      source:</span> <span class="hljs-string">&quot;leancloud&quot;</span><br><span class="hljs-symbol">      format:</span> <span class="hljs-string">&quot;&#123;&#125; 次&quot;</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">statistics:</span><br><span class="hljs-symbol">    enable:</span> true<br><span class="hljs-symbol">    source:</span> <span class="hljs-string">&quot;leancloud&quot;</span><br><span class="hljs-symbol">    pv_format:</span> <span class="hljs-string">&quot;总访问量 &#123;&#125; 次&quot;</span><br><span class="hljs-symbol">    uv_format:</span> <span class="hljs-string">&quot;总访客数 &#123;&#125; 人&quot;</span><br></code></pre></td></tr></table></figure></p></li><li><p>再次在shell中输入如下内容，通过浏览器访问浏览器访问 <ahref="http://localhost:4000">http://localhost:4000</a>查看是否在页面下方显示访问情况 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure></p><center><p><img src="info.jpg" alt="info" width="80%"/></p></center></li></ul><h3 id="设置latex公式">6. 设置latex公式</h3><p>详见 <ahref="https://fluid-dev.github.io/hexo-fluid-docs/guide/#latex-数学公式">https://fluid-dev.github.io/hexo-fluid-docs/guide/#latex-数学公式</a></p><h3 id="上传至github">7. 上传至Github</h3><ul><li><p>安装hexo-deployer-git <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure></p></li><li><p>如图所示，获得Personal accesstokens，并注意在获得tokens时要选择Tokens(classic)并勾选repo</p></li><li><p>打开blog/_config.yml配置文件,设置部署参数 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">deploy:<br>  <span class="hljs-built_in">type</span>: git<br>  repo: https://&lt;你的Personal access tokens&gt;@github.com/&lt;你的Github用户名&gt;/&lt;你的Github用户名&gt;.github.io.git<br>  branch: main<br></code></pre></td></tr></table></figure></p></li><li><p>在shell中输入如下内容，通过浏览器访问浏览器访问(https://<你的Github用户名>.github.io/)查看是否部署成功<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g -d<br></code></pre></td></tr></table></figure></p></li></ul><h2 id="二添加删除或修改博客文章">二、添加删除或修改博客文章</h2><h3 id="添加博客文章">1. 添加博客文章</h3><ul><li><p>方法1:在shell中转到项目文件夹blog，并在shell中输入如下内容，添加名字为new_article的博客文章，在blog/source/_posts中找到new_article.md和new_article文件夹，对其修改即可添加博客文章<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo new post new_article<br></code></pre></td></tr></table></figure></p></li><li><p>方法2:在blog/source/_posts中创建一个文件夹，再在此文件夹里创建new_article.md和new_article文件夹，对其修改即可添加博客文章（也可以直接在blog/source/_posts里创建new_article.md和new_article文件夹）</p></li></ul><h3 id="删除或修改博客文章">2. 删除或修改博客文章</h3><p>在blog/source/_posts中找到xxx.md和xxx文件夹，对其删除或修改即可</p><h3 id="插入代码">3. 插入代码</h3><p>在md里输入如下代码即可</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">``` python<br>import numpy as np<br>a = 1<br>print(a)<br>```<br></code></pre></td></tr></table></figure><h3 id="插入图片">4. 插入图片</h3><ul><li><p>方法1: 在xxx文件夹中存放test.jpg，并在xxx.md中输入以下代码</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">&#123;% asset_img test.jpg example %&#125;<br></code></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">&lt;center&gt;<br>&lt;img src=&quot;test.jpg&quot; alt=&quot;图片描述&quot; width=&quot;50%&quot;/&gt;<br>&lt;/center&gt;<br></code></pre></td></tr></table></figure></li><li><p>方法2: 找到图片的网址为xxx，并在xxx.md中输入以下代码<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">&lt;center&gt;<br>&lt;img src=&quot;并在xxx.md中输入以下代码&quot; alt=&quot;图片名称&quot;   width=&quot;50%&quot;/&gt;<br>&lt;/center&gt;<br></code></pre></td></tr></table></figure></p></li></ul><h3id="在shell中输入如下内容通过浏览器访问httplocalhost4000-查看是否更改成功">5.在shell中输入如下内容，通过浏览器访问<ahref="http://localhost:4000">http://localhost:4000</a>查看是否更改成功</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo g<br>hexo s<br></code></pre></td></tr></table></figure><h2 id="三参考内容">三、参考内容</h2><h3 id="httpsblog.csdn.netyaorongkearticledetails119089190">1. <ahref="https://blog.csdn.net/yaorongke/article/details/119089190">https://blog.csdn.net/yaorongke/article/details/119089190</a></h3><h3 id="httpszhcano.github.ioleancloudhexo开启评论和文章阅读量">2. <ahref="https://zhcano.github.io/LeanCloud+Hexo开启评论和文章阅读量/">https://zhcano.github.io/LeanCloud+Hexo开启评论和文章阅读量/</a></h3><h3 id="httpsfluid-dev.github.iohexo-fluid-docsguide">3. <ahref="https://fluid-dev.github.io/hexo-fluid-docs/guide/">https://fluid-dev.github.io/hexo-fluid-docs/guide/</a></h3>]]></content>
    
    
    <categories>
      
      <category>Instruction</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Github Pages Deployment</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
